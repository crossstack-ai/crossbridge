# ============================================================================
# CrossBridge Unified Configuration File
# ============================================================================
# Single source of truth for all CrossBridge configuration
# Supports environment variable substitution: ${VAR_NAME:-default_value}
# ============================================================================

crossbridge:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # CORE SETTINGS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  # Operational mode: 'migration' or 'observer'
  # - migration: Active test discovery and framework transformation
  # - observer: Continuous intelligence and monitoring (default)
  mode: observer
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # APPLICATION TRACKING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Used for version-based coverage analysis and test tracking
  
  application:
    # Product/Application name (e.g., "PaymentAPI", "WebPortal")
    # Override with: PRODUCT_NAME or CROSSBRIDGE_PRODUCT_NAME
    product_name: ${PRODUCT_NAME:-CrossBridgeApp}
    
    # Application version being tested (e.g., "2.1.0", "v3.0.0-beta")
    # Override with: APP_VERSION or CROSSBRIDGE_APP_VERSION
    # CI/CD Tip: export APP_VERSION=$(git describe --tags)
    application_version: ${APP_VERSION:-v0.2.0}
    
    # Environment name (e.g., "dev", "staging", "production")
    # Override with: ENVIRONMENT or CROSSBRIDGE_ENVIRONMENT
    environment: ${ENVIRONMENT:-test}
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DATABASE CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # PostgreSQL database for test events, coverage, and intelligence
  
  database:
    enabled: true
    
    # Database connection settings
    # Override with CROSSBRIDGE_DB_* environment variables
    host: ${CROSSBRIDGE_DB_HOST:-10.55.12.99}
    port: ${CROSSBRIDGE_DB_PORT:-5432}
    database: ${CROSSBRIDGE_DB_NAME:-udp-native-webservices-automation}
    user: ${CROSSBRIDGE_DB_USER:-postgres}
    password: ${CROSSBRIDGE_DB_PASSWORD:-admin}
    
    # Connection pool settings (advanced)
    # pool_size: 10
    # max_overflow: 20
    # pool_timeout: 30
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # SIDECAR OBSERVER HOOKS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Automatic hook integration during test migration
  
  sidecar_hooks:
    # Enable/disable sidecar observer hooks
    enabled: true
    
    # Automatically integrate hooks during migration
    # When true: hooks are configured automatically in migrated tests
    # When false: manual setup required
    auto_integrate: true
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # TEST TRANSLATION/MIGRATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Settings for framework-to-framework test transformation
  
  translation:
    # Translation mode
    # - assistive: Human reviews each translation (default, safest)
    # - automated: Automatic with confidence checks (faster)
    # - batch: Bulk translation for large codebases (fastest)
    mode: assistive
    
    # AI-powered translation enhancement
    use_ai: false              # Enable AI refinement (requires credits)
    max_credits: 100           # Maximum AI credits to spend per session
    confidence_threshold: 0.7  # Minimum confidence to auto-apply (0.0-1.0)
    
    # Code validation
    validation_level: strict   # strict, lenient, skip
    preserve_comments: true    # Keep original comments in translated code
    inject_todos: true         # Add TODO comments for manual review items
    
    # Performance tuning
    max_workers: 10            # Parallel translation threads (1-20)
    commit_batch_size: 10      # Files per batch commit (5-20)
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # AI / LLM CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # AI provider settings for enhanced translation and analysis
  
  ai:
    # Enable AI features
    enabled: false
    
    # Provider: 'openai', 'anthropic', or 'custom'
    provider: openai
    
    # API credentials (NEVER commit real keys to git!)
    # Use environment variable: export OPENAI_API_KEY=sk-...
    # Use environment variable: export ANTHROPIC_API_KEY=sk-ant-...
    api_key: ${OPENAI_API_KEY}
    
    # Custom endpoint (for enterprise/on-prem deployments)
    endpoint: null
    
    # Model selection
    # OpenAI: gpt-3.5-turbo (fast, cheap), gpt-4 (better quality)
    # Anthropic: claude-3-sonnet, claude-3-opus
    model: gpt-3.5-turbo
    
    # Data residency region (for compliance)
    region: US
    
    # Model parameters
    temperature: 0.7           # Creativity (0.0-1.0, lower = more deterministic)
    max_tokens: 2048           # Max response length
    timeout: 60                # Request timeout in seconds
    
    # â”€â”€ AI Semantic Engine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Semantic search, duplicate detection, and smart test selection
    semantic_engine:
      enabled: true
      
      # Embedding configuration
      embedding:
        # Provider: 'openai', 'anthropic', 'huggingface', 'local'
        provider: openai
        
        # Model for embeddings
        # OpenAI: text-embedding-3-large (3072d), text-embedding-3-small (1536d)
        # Anthropic: TBD (when available)
        model: text-embedding-3-large
        
        # Embedding version (for reindexing detection)
        version: v2-text+ast
        
        # Enable AST augmentation (adds code structure to text)
        ast_augmentation: true
        
        # Batch size for embedding generation
        batch_size: 100
        
        # API settings
        api_key: ${OPENAI_API_KEY}
        timeout: 30
        max_retries: 3
      
      # Vector store configuration
      vector_store:
        # Type: 'pgvector' (PostgreSQL), 'faiss' (local), 'chroma' (future)
        type: pgvector
        
        # For pgvector: Uses main database connection
        # For faiss: Local file storage
        storage_path: ./data/vectors
        
        # Index configuration
        index_type: ivfflat      # ivfflat (pgvector), hnsw (future)
        distance_metric: cosine  # cosine, l2, ip
        
        # Performance tuning
        probes: 10               # IVF index probes (1-100, higher = more accurate)
        maintenance_interval: 3600  # Seconds between index maintenance
      
      # Semantic search configuration
      search:
        # Default search parameters
        default_top_k: 10
        min_confidence: 0.5
        
        # Confidence calibration
        calibration:
          enabled: true
          sample_size_factor: 30  # log1p(sample_count) / log1p(30)
        
        # Result caching (reduces API calls)
        cache:
          enabled: true
          ttl: 3600              # Seconds
          max_size: 1000         # Max cached queries
      
      # Duplicate detection
      duplicate_detection:
        enabled: true
        
        # Thresholds
        similarity_threshold: 0.9    # Minimum similarity for duplicates
        confidence_threshold: 0.8    # Minimum confidence for duplicates
        
        # Clustering settings
        clustering:
          enabled: true
          algorithm: dbscan      # dbscan, hdbscan
          min_cluster_size: 3
          eps: 0.3               # Distance threshold
          metric: cosine
      
      # Smart test selection
      test_selection:
        enabled: true
        
        # Scoring weights (must sum to 1.0)
        weights:
          semantic_similarity: 0.4   # Code/test semantic overlap
          coverage_relevance: 0.3    # Code coverage mapping
          failure_history: 0.2       # Historical failure patterns
          flakiness_penalty: 0.1     # Flaky test penalty
        
        # Selection parameters
        min_score: 0.3           # Minimum selection score
        default_budget: 50       # Default max tests to select
        include_flaky: false     # Include flaky tests by default
        
        # Priority levels
        priority_thresholds:
          critical: 0.8
          high: 0.6
          medium: 0.4
          low: 0.0
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # EXECUTION INTELLIGENCE - LOG SOURCES
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Configure automation logs (mandatory) and application logs (optional)
  # Priority: CLI arguments > Config file > Framework defaults
  
  execution:
    # Framework being tested (for default log path resolution)
    framework: selenium  # selenium, pytest, robot, playwright, cypress, etc.
    
    # Source root directory (for code analysis)
    source_root: ./src/test/java
    
    # Log sources configuration
    logs:
      # Automation logs (MANDATORY - test framework outputs)
      # These are REQUIRED for analysis and will cause failure if missing
      automation:
        - ./target/surefire-reports     # Java/Maven test reports
        - ./logs/test.log                # Test execution logs
      
      # Application logs (OPTIONAL - product/service logs)
      # When present, enables +0.15 confidence boost via log correlation
      # Missing application logs will NOT cause failures
      application:
        - ./app/logs/service.log         # Backend service logs
        - ./logs/backend.log             # Application logs
        # - ./logs/api.log               # API server logs
        # - ./logs/database.log          # Database logs
    
    # â”€â”€ Application Log Ingestion (JSON Structured Logs) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Universal adapter for JSON-formatted application logs
    log_ingestion:
      enabled: true
      
      # Log format adapters (JSON, ELK, Fluentd, plain text)
      adapters:
        # JSON structured logs (primary adapter)
        json:
          enabled: true
          
          # Custom field mappings (optional)
          # Override default field names to match your log format
          field_mapping:
            # timestamp_fields: [timestamp, '@timestamp', time]
            # level_fields: [level, severity, log_level]
            # message_fields: [message, msg, text]
            # service_fields: [service, app, application]
            # component_fields: [component, logger, class]
        
        # Plain text logs (future enhancement)
        plaintext:
          enabled: false
      
      # Sampling configuration (high-volume log management)
      sampling:
        enabled: true
        
        # Sampling rates by log level (0.0-1.0)
        rates:
          debug: 0.01    # Sample 1% of DEBUG logs
          info: 0.01     # Sample 1% of INFO logs
          warn: 0.1      # Sample 10% of WARN logs
          error: 1.0     # Sample 100% of ERROR logs (always)
          fatal: 1.0     # Sample 100% of FATAL logs (always)
        
        # Rate limiting (events per second)
        max_events_per_second: 1000
        
        # Adaptive sampling (adjust rates based on load)
        adaptive: true
        adaptation_window: 60  # seconds
        
        # Pattern-based sampling control
        # always_sample_patterns: []  # Always sample logs matching these keywords
        # never_sample_patterns: []   # Never sample logs matching these keywords
      
      # Log correlation with test execution
      correlation:
        enabled: true
        
        # Correlation strategies (tried in order)
        strategies:
          - trace_id         # Best: distributed trace ID
          - execution_id     # High: test execution ID
          - timestamp        # Good: time window matching
          - service          # Moderate: service/component name
        
        # Timestamp correlation window (seconds)
        timestamp_window: 5
      
      # Storage configuration
      storage:
        enabled: true
        
        # Store in PostgreSQL (application_logs table)
        backend: postgresql
        
        # Batch insert optimization
        batch_size: 100
        batch_timeout: 5  # seconds
      
      # Signal extraction for anomaly detection
      signals:
        enabled: true
        
        # Extract these signals from logs
        extract:
          - error_occurrence       # Is this an error?
          - error_type            # Exception/error type
          - timeout_indicator     # Timeout-related?
          - retry_indicator       # Retry-related?
          - circuit_breaker       # Circuit breaker event?
          - performance_metric    # Slow operation?
          - message_entropy       # Message uniqueness
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FLAKY TEST DETECTION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Machine learning-based flaky test detection
  
  flaky_detection:
    enabled: true
    
    # Isolation Forest parameters
    n_estimators: 200          # Number of trees in forest
    contamination: 0.1         # Expected ratio of flaky tests (10%)
    random_state: 42           # For reproducible results
    
    # Confidence thresholds
    min_executions_reliable: 15    # Minimum runs for reliable detection
    min_executions_confident: 30   # Runs for full confidence
    min_confidence_threshold: 0.5  # Minimum confidence to classify (0.0-1.0)
    
    # Feature engineering
    execution_window_size: 50  # Number of recent runs to analyze
    recent_window_size: 10     # For temporal pattern detection
    
    # Model management
    auto_retrain: true         # Automatically retrain model
    retrain_threshold: 100     # Retrain after N new tests
    model_version: "1.0.0"     # Model version tracking
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # OBSERVER MODE
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Continuous intelligence and monitoring features
  
  observer:
    # Automatically detect new test files/cases
    auto_detect_new_tests: true
    
    # Update coverage graph continuously
    update_coverage_graph: true
    
    # Detect test drift and behavior changes
    detect_drift: true
    
    # Flaky test failure rate threshold (0.0-1.0)
    # Tests with failure rate above this are flagged
    flaky_threshold: 0.15      # 15% failure rate
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DRIFT DETECTION & MONITORING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Confidence drift detection and monitoring for test stability tracking
  
  drift_detection:
    # Enable confidence drift tracking
    enabled: true
    
    # Database backend for drift data storage
    # Options: sqlite (default, file-based) or postgres (production, scalable)
    backend: sqlite
    
    # â”€â”€ SQLite Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Used when backend=sqlite (default for development/testing)
    sqlite:
      db_path: ./data/drift_tracking.db
    
    # â”€â”€ PostgreSQL Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Used when backend=postgres (recommended for production)
    # Supports environment variable substitution
    postgres:
      host: ${POSTGRES_HOST:-localhost}
      port: ${POSTGRES_PORT:-5432}
      database: ${POSTGRES_DB:-crossbridge}
      user: ${POSTGRES_USER:-crossbridge}
      password: ${POSTGRES_PASSWORD:-}
      schema: ${POSTGRES_SCHEMA:-drift}
      
      # Connection pooling (for production scalability)
      pool:
        min_connections: 1
        max_connections: 10
    
    # â”€â”€ Drift Analysis Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    analysis:
      # Time window for drift detection (days)
      window_days: 30
      
      # Minimum measurements required for reliable drift analysis
      min_measurements: 5
      
      # Drift severity thresholds (percentage change in confidence)
      # Used to classify drift severity levels
      thresholds:
        low: 5        # 5% change = LOW severity
        moderate: 10  # 10% change = MODERATE severity
        high: 20      # 20% change = HIGH severity
        critical: 30  # 30% change = CRITICAL severity
    
    # â”€â”€ Alert Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Automatic alert generation for significant drift
    alerts:
      # Create alerts only for these severity levels
      # Options: [low, moderate, high, critical]
      alert_on_severity:
        - high
        - critical
      
      # Alert notifications (future enhancement)
      notifications:
        enabled: false
        # slack_webhook: ${SLACK_WEBHOOK_URL}
        # teams_webhook: ${TEAMS_WEBHOOK_URL}
        # email_recipients: ${ALERT_EMAIL_LIST}
    
    # â”€â”€ Data Maintenance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Automatic cleanup and optimization
    maintenance:
      # Automatically cleanup old data
      auto_cleanup: true
      
      # Data retention policies (days)
      # Older data will be automatically purged
      retention:
        measurements: 90   # Keep confidence measurements for 90 days
        analysis_cache: 30 # Keep analysis results cache for 30 days
        alerts: 60         # Keep drift alerts for 60 days
      
      # Database optimization
      vacuum:
        enabled: true
        schedule: weekly   # Run vacuum optimization weekly
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # INTELLIGENCE FEATURES
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # AI-powered analysis and recommendations
  
  intelligence:
    # Enable AI-powered intelligence
    ai_enabled: true
    
    # Missing coverage detection
    # Identifies code areas without test coverage
    detect_coverage_gaps: true
    
    # Redundant test detection
    # Finds tests with overlapping coverage
    detect_redundant_tests: true
    
    # Risk-based execution recommendations
    # Suggests which tests to run based on code changes
    risk_based_recommendations: true
    
    # â”€â”€ Advanced Failure Classification Rules (NEW) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Framework-specific rules for intelligent failure classification
    # All rules are in single config file (no separate YAML files needed)
    # System automatically loads rules based on execution.framework setting
    
    rules:
      # Rules for Selenium (Python/Java UI automation)
      selenium:
        - id: SEL_001
          description: Element locator not found or stale
          match_any:
            - NoSuchElementException
            - StaleElementReferenceException
            - ElementNotInteractableException
          failure_type: AUTOMATION_DEFECT
          confidence: 0.90
          priority: 10
        
        - id: SEL_002
          description: Timeout waiting for element or condition
          match_any:
            - TimeoutException
            - "wait timeout"
            - "timed out waiting"
          failure_type: AUTOMATION_DEFECT
          confidence: 0.85
          priority: 15
        
        - id: SEL_PROD_001
          description: Server errors (5xx)
          match_any:
            - "500 Internal Server Error"
            - "502 Bad Gateway"
            - "503 Service Unavailable"
          failure_type: PRODUCT_DEFECT
          confidence: 0.95
          priority: 5
      
      # Rules for Pytest (Python unit/integration tests)
      pytest:
        - id: PYT_001
          description: Fixture failures
          match_any:
            - fixture
            - "@pytest.fixture"
            - setup failed
          failure_type: AUTOMATION_DEFECT
          confidence: 0.85
          priority: 15
        
        - id: PYT_PROD_001
          description: Assertion failures
          match_any:
            - AssertionError
            - assert
          excludes:
            - fixture
          failure_type: PRODUCT_DEFECT
          confidence: 0.90
          priority: 10
      
      # Rules for Robot Framework
      robot:
        - id: ROB_001
          description: Keyword failures
          match_any:
            - "Keyword"
            - "No keyword with name"
          failure_type: AUTOMATION_DEFECT
          confidence: 0.88
          priority: 12
        
        - id: ROB_PROD_001
          description: Test assertions failed
          match_any:
            - "should be equal"
            - "should contain"
            - "should not"
          failure_type: PRODUCT_DEFECT
          confidence: 0.90
          priority: 10
      
      # Generic fallback rules (used when framework-specific rules don't match)
      generic:
        - id: GEN_PROD_001
          description: Null pointer / reference errors
          match_any:
            - NullPointerException
            - NullReferenceException
            - "is null"
            - "'NoneType'"
          failure_type: PRODUCT_DEFECT
          confidence: 0.85
          priority: 20
        
        - id: GEN_ENV_001
          description: Connection / network issues
          match_any:
            - Connection refused
            - Connection timeout
            - UnknownHostException
            - ECONNREFUSED
          failure_type: ENVIRONMENT_ISSUE
          confidence: 0.90
          priority: 15
      
      # â”€â”€â”€ Note: Complete rule sets available in docs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # This shows basic examples. For full rule sets (14-20 rules per framework):
      # - See: core/execution/intelligence/rules/*.yaml
      # - Or use: crossbridge rules list --framework <name>
      # - Add your custom rules here following the same structure
      
      # All 12 frameworks supported:
      # selenium, pytest, robot, playwright, restassured, cypress,
      # cucumber, behave, junit, testng, specflow, nunit, generic
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FRAMEWORK-SPECIFIC SETTINGS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Configuration for each supported test framework
  # Multi-Framework Support: 12 frameworks across 5 languages
  
  frameworks:
    
    # â”€â”€â”€ pytest (Python Unit/Integration) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pytest:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API/HTTP calls
      auto_instrument_ui_interactions: false  # Track UI interactions
      
      # Network monitoring
      capture_network_traffic: true       # Capture request/response data
      
      # Tracking options
      track_keywords: true                # Track pytest fixtures/markers
      track_api_calls: true               # Track API endpoint coverage
    
    
    # â”€â”€â”€ JUnit (Java Unit Testing) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    junit:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls
      auto_instrument_ui_interactions: false  # Track UI interactions
      
      # Tracking options
      track_keywords: true                # Track @Test annotations
      track_api_calls: true               # Track API endpoint coverage
    
    
    # â”€â”€â”€ TestNG (Java Enterprise Testing) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    testng:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls
      auto_instrument_ui_interactions: false  # Track UI interactions
      
      # Tracking options
      track_keywords: true                # Track @Test annotations
      track_api_calls: true               # Track API endpoint coverage
      track_groups: true                  # Track test groups
    
    
    # â”€â”€â”€ NUnit (C# Unit Testing) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    nunit:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls
      auto_instrument_ui_interactions: false  # Track UI interactions
      
      # Tracking options
      track_keywords: true                # Track [Test] attributes
      track_api_calls: true               # Track API endpoint coverage
    
    
    # â”€â”€â”€ SpecFlow (C# BDD) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    specflow:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls in steps
      auto_instrument_ui_interactions: true  # Track UI interactions in steps
      
      # Tracking options
      track_keywords: true                # Track Gherkin keywords
      track_api_calls: true               # Track API endpoint coverage
      parse_gherkin: true                 # Parse .feature files
    
    
    # â”€â”€â”€ Playwright (JavaScript/TypeScript E2E) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    playwright:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls
      auto_instrument_ui_interactions: true  # Track page interactions
      
      # Network monitoring
      capture_network_traffic: true       # Capture network activity
      
      # Tracking options
      track_keywords: true                # Track test annotations
      track_api_calls: true               # Track route handlers
    
    
    # â”€â”€â”€ Robot Framework (Keyword-Driven) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    robot:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track RequestsLibrary calls
      auto_instrument_ui_interactions: true  # Track SeleniumLibrary actions
      
      # Network monitoring
      capture_network_traffic: false      # Not supported by default
      
      # Tracking options
      track_keywords: true                # Track custom keywords
      track_api_calls: true               # Track API test cases
    
    
    # â”€â”€â”€ RestAssured (Java REST API Testing) ðŸ†• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    restassured:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track REST API calls
      
      # Network monitoring
      capture_network_traffic: true       # Capture request/response data
      
      # Tracking options
      track_keywords: true                # Track @Test annotations
      track_api_calls: true               # Track API endpoint coverage
      track_groups: true                  # Track TestNG groups
    
    
    # â”€â”€â”€ Selenium Python (Python UI Automation) ðŸ†• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    selenium_python:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: false    # Focus on UI testing
      auto_instrument_ui_interactions: true  # Track WebDriver actions
      
      # Tracking options
      track_keywords: true                # Track pytest markers
      track_api_calls: false              # Not primary use case
      ast_extraction: true                # Full AST parsing enabled
    
    
    # â”€â”€â”€ Selenium Java (Java UI Automation) ðŸ†• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    selenium_java:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: false    # Focus on UI testing
      auto_instrument_ui_interactions: true  # Track WebDriver actions
      
      # Tracking options
      track_keywords: true                # Track @Test annotations
      track_api_calls: false              # Not primary use case
      track_groups: true                  # Track TestNG groups
    
    
    # â”€â”€â”€ Cucumber (BDD Gherkin) ðŸ†• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cucumber:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls in steps
      auto_instrument_ui_interactions: true  # Track UI interactions in steps
      
      # Tracking options
      track_keywords: true                # Track Gherkin keywords
      track_api_calls: true               # Track API endpoint coverage
      parse_gherkin: true                 # Parse .feature files
      detect_step_patterns: true          # Detect API/UI patterns in steps
    
    
    # â”€â”€â”€ Behave (Python BDD) ðŸ†• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    behave:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track API calls in steps
      auto_instrument_ui_interactions: true  # Track UI interactions in steps
      
      # Tracking options
      track_keywords: true                # Track Gherkin keywords
      track_api_calls: true               # Track API endpoint coverage
      parse_gherkin: true                 # Parse .feature files
      detect_step_patterns: true          # Detect API/UI patterns in steps
    
    
    # â”€â”€â”€ Cypress (JavaScript E2E) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cypress:
      enabled: true
      
      # Automatic instrumentation
      auto_instrument_api_calls: true     # Track cy.request() calls
      auto_instrument_ui_interactions: true  # Track cy.get(), cy.click(), etc.
      
      # Network monitoring
      capture_network_traffic: true       # Capture XHR/Fetch requests
      
      # Tracking options
      track_keywords: true                # Track custom commands
      track_api_calls: true               # Track API intercepts
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # LOGGING CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Logging levels and output settings
  
  logging:
    # Global log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
    # DEBUG: Detailed diagnostic information (verbose)
    # INFO: General informational messages (default)
    # WARNING: Warning messages for potential issues
    # ERROR: Error messages for failures
    # CRITICAL: Critical errors requiring immediate attention
    level: INFO
    
    # Log format: simple, detailed, json
    # simple: Timestamp + level + message
    # detailed: Adds module, function, line number (default)
    # json: Machine-readable JSON format for log aggregation
    format: detailed
    
    # File logging
    log_to_file: true
    log_file_path: logs/crossbridge.log  # Relative or absolute path
    
    # Console logging (stdout)
    log_to_console: true
    
    # Log file rotation
    max_file_size_mb: 10    # Rotate after 10MB
    backup_count: 5         # Keep 5 backup files
    
    # Component-specific log levels (override global level)
    # Useful for debugging specific modules without flooding logs
    translation_level: null  # null = use global level
    ai_level: null           # Set to DEBUG for AI troubleshooting
    database_level: null     # Set to DEBUG for SQL query logging
    observer_level: null     # Set to DEBUG for observer diagnostics


# ============================================================================
# ENVIRONMENT-SPECIFIC OVERRIDES (Optional)
# ============================================================================
# You can maintain separate config files for different environments:
# - crossbridge.dev.yml
# - crossbridge.staging.yml
# - crossbridge.production.yml
# 
# Load with: export CROSSBRIDGE_CONFIG=crossbridge.staging.yml
# ============================================================================


  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # PERFORMANCE PROFILING (NEW)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Passive, framework-agnostic performance profiling for test execution
  # Disabled by default - explicitly enable when needed
  
  profiling:
    # Enable/disable performance profiling (DEFAULT: false)
    # Override with: CROSSBRIDGE_PROFILING=true/false
    enabled: false
    
    # Profiling mode: 'passive' (observer) or 'active' (future)
    mode: passive
    
    # Sampling rate: 1.0 = 100%, 0.5 = 50% of events
    sampling_rate: 1.0
    
    # â”€â”€ Collectors â”€â”€
    # Control which metrics are collected
    collectors:
      test_lifecycle: true      # Test start/end, setup/teardown timing
      webdriver: true           # Selenium WebDriver command timing
      http: true                # API/HTTP request timing
      system_metrics: false     # CPU/Memory usage (optional, can be expensive)
    
    # â”€â”€ Storage Backend â”€â”€
    # Options: 'none', 'local', 'postgres', 'influxdb'
    storage:
      backend: none  # DEFAULT: none (disabled)
      
      # Local file storage (JSONL format)
      local:
        path: .crossbridge/profiles
      
      # PostgreSQL storage (Grafana-friendly schema)
      postgres:
        host: ${CROSSBRIDGE_DB_HOST:-localhost}
        port: ${CROSSBRIDGE_DB_PORT:-5432}
        database: ${CROSSBRIDGE_DB_NAME:-crossbridge}
        user: ${CROSSBRIDGE_DB_USER:-crossbridge}
        password: ${CROSSBRIDGE_DB_PASSWORD:-crossbridge}
        schema: profiling  # Schema name for profiling tables
      
      # InfluxDB time-series storage (on-prem)
      influxdb:
        url: ${INFLUXDB_URL:-http://localhost:8086}
        org: ${INFLUXDB_ORG:-crossbridge}
        bucket: ${INFLUXDB_BUCKET:-profiling}
        token: ${INFLUX_TOKEN}
    
    # â”€â”€ Grafana Integration â”€â”€
    grafana:
      enabled: false
      datasource: postgres  # 'postgres' or 'influxdb'


# ============================================================================
# COMMON CONFIGURATION EXAMPLES
# ============================================================================

# Example 1: Local Development
# -----------------------------------------------------------------------------
# crossbridge:
#   mode: observer
#   database:
#     host: localhost
#     password: dev_password
#   ai:
#     enabled: false  # Save credits during development
#   flaky_detection:
#     min_executions_reliable: 5  # Lower threshold for faster feedback

# Example 2: CI/CD Pipeline
# -----------------------------------------------------------------------------
# crossbridge:
#   mode: observer
#   application:
#     application_version: ${CI_COMMIT_TAG}  # From GitLab CI
#     environment: ${CI_ENVIRONMENT_NAME}
#   translation:
#     mode: automated  # Faster for CI
#     validation_level: lenient
#   sidecar_hooks:
#     auto_integrate: true

# Example 3: Production Monitoring
# -----------------------------------------------------------------------------
# crossbridge:
#   mode: observer
#   application:
#     environment: production
#   observer:
#     flaky_threshold: 0.05  # Stricter in production
#   intelligence:
#     risk_based_recommendations: true
#   flaky_detection:
#     min_executions_confident: 50  # More data for confidence

# Example 4: Performance Profiling Enabled (PostgreSQL + Grafana)
# -----------------------------------------------------------------------------
# crossbridge:
#   profiling:
#     enabled: true
#     storage:
#       backend: postgres
#       postgres:
#         host: 10.60.67.247
#         port: 5432
#         database: cbridge-unit-test-db
#         user: postgres
#         password: admin
#     grafana:
#       enabled: true
#       datasource: postgres


# ============================================================================
# PRODUCTION RUNTIME CONFIGURATION
# ============================================================================
# Rate limiting, retry policies, and health checks for production robustness

runtime:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RATE LIMITING CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Token bucket algorithm for fair per-user/org throttling
  
  rate_limiting:
    enabled: true
    
    # Default rate limits per operation type
    defaults:
      # Semantic search rate limits
      search:
        capacity: 30              # Tokens per window
        window_seconds: 60        # Refill window
      
      # Test transformation rate limits
      transform:
        capacity: 10
        window_seconds: 60
      
      # Embedding generation rate limits
      embed:
        capacity: 60
        window_seconds: 60
      
      # AI code generation rate limits
      ai_generate:
        capacity: 20
        window_seconds: 60
      
      # Health check rate limits
      health_check:
        capacity: 100
        window_seconds: 60
    
    # Cleanup settings
    cleanup_threshold: 1000       # Clean up buckets when count exceeds this
    
    # Per-user/org override examples (optional)
    # overrides:
    #   user:12345:
    #     search:
    #       capacity: 100
    #       window_seconds: 60
    #   org:premium:
    #     transform:
    #       capacity: 50
    #       window_seconds: 60
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RETRY POLICY CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Exponential backoff with jitter for transient failures
  
  retry:
    enabled: true
    
    # Default retry policy for most operations
    default_policy:
      max_attempts: 3             # Maximum retry attempts
      base_delay: 0.5             # Initial delay in seconds
      max_delay: 5.0              # Maximum delay cap
      exponential_base: 2.0       # Exponential multiplier (2^attempt)
      jitter: true                # Add randomness to prevent thundering herd
    
    # Expensive operations policy (AI, embeddings)
    expensive_policy:
      max_attempts: 5
      base_delay: 1.0
      max_delay: 10.0
      exponential_base: 2.0
      jitter: true
    
    # Quick retry policy (database, cache)
    quick_policy:
      max_attempts: 2
      base_delay: 0.1
      max_delay: 1.0
      exponential_base: 2.0
      jitter: true
    
    # Conservative retry policy (critical operations)
    conservative_policy:
      max_attempts: 3
      base_delay: 2.0
      max_delay: 30.0
      exponential_base: 3.0
      jitter: true
    
    # Retryable HTTP status codes
    retryable_codes:
      - 429  # Rate limit exceeded
      - 500  # Internal server error
      - 502  # Bad gateway
      - 503  # Service unavailable
      - 504  # Gateway timeout
    
    # Timeout for network operations (seconds)
    network_timeout: 30
  
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # HEALTH CHECK CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Provider health monitoring for proactive failure detection
  
  health_checks:
    enabled: true
    
    # Global health check settings
    interval: 30                  # Check interval in seconds
    timeout: 10                   # Health check timeout
    failure_threshold: 3          # Failures before marking degraded
    
    # Providers to monitor
    providers:
      # AI provider health checks
      ai_provider:
        enabled: true
        check_type: embed         # Test method: embed, generate, ping
        interval: 60              # Override global interval
        timeout: 15               # Override global timeout
      
      # Embedding provider health checks
      embedding_provider:
        enabled: true
        check_type: embed
        interval: 60
        timeout: 10
      
      # Vector store health checks
      vector_store:
        enabled: true
        check_type: ping          # Methods: ping, health_check, get_collection
        interval: 30
        timeout: 5
      
      # Database health checks
      database:
        enabled: true
        check_type: ping
        interval: 20
        timeout: 5
      
      # Custom health checks
      # custom:
      #   enabled: true
      #   check_type: callable
      #   callable: my_module.health_check_function
      #   interval: 45
      #   timeout: 10
    
    # Degraded mode behavior
    degraded_mode:
      # Continue operating with limited functionality
      continue_on_degraded: true
      
      # Disable non-critical features when degraded
      disable_features:
        - flaky_detection
        - coverage_analysis
      
      # Alert configuration (optional)
      # alerts:
      #   slack_webhook: https://hooks.slack.com/...
      #   email: ops@example.com


  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DEBUGGABLE SIDECAR RUNTIME
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Resilient, low-overhead sidecar observer for test execution monitoring
  # NEVER blocks or crashes the main process
  # 
  # Design Principles:
  # 1. Fail-Open: Errors never propagate to test execution
  # 2. Bounded Resources: Hard limits on CPU, memory, queue size
  # 3. Sampling-First: Process only a fraction of events
  # 4. Load Shedding: Drop events when overwhelmed
  # 5. Observable: Metrics, health endpoints, structured logging
  
  sidecar:
    # â”€â”€ Global Enable/Disable â”€â”€
    # Kill switch for entire sidecar runtime
    enabled: true
    
    # â”€â”€ Fail-Open Execution â”€â”€
    # ALL operations wrapped in @safe_observe decorator
    fail_open:
      enabled: true                      # Enable fail-open behavior
      log_errors: true                   # Log errors to structured logs
      track_metrics: true                # Track error metrics
      max_error_rate: 0.1                # Warn if error rate > 10%
    
    # â”€â”€ Event Queue Configuration â”€â”€
    # Bounded queue with load shedding
    queue:
      max_size: ${SIDECAR_QUEUE_SIZE:-5000}    # Maximum events in queue
      max_event_age_seconds: 300                # Drop events older than 5 min
      drop_on_full: true                        # Drop new events when full
      drain_interval_seconds: 1.0               # Queue drain interval
      batch_size: 100                           # Events per batch
    
    # â”€â”€ Sampling Configuration â”€â”€
    # Sample events to reduce processing load
    sampling:
      enabled: true
      
      # Per-event-type sampling rates (0.0 to 1.0)
      rates:
        events: ${SIDECAR_SAMPLE_EVENTS:-0.1}        # 10% of events
        logs: ${SIDECAR_SAMPLE_LOGS:-0.05}           # 5% of logs
        profiling: ${SIDECAR_SAMPLE_PROFILING:-0.01} # 1% profiling samples
        metrics: 1.0                                  # 100% metrics (always)
        traces: 0.05                                  # 5% of traces
      
      # Per-signal sampling (override event-type rates)
      signals:
        test_events: 0.2           # 20% test events (important)
        perf_metrics: 0.05         # 5% performance metrics
        debug_logs: 0.01           # 1% debug logs
        flaky_signals: 0.5         # 50% flaky detection signals
        error_logs: 1.0            # 100% errors (always sample)
      
      # Adaptive sampling (boost on anomalies)
      adaptive:
        enabled: true
        boost_factor: 5.0          # 5x increase on anomaly
        boost_duration_seconds: 60 # Boost duration
        anomaly_threshold: 0.95    # Trigger when confidence > 95%
    
    # â”€â”€ Resource Budgets â”€â”€
    # Hard limits to protect main process
    resources:
      # CPU budget (percentage)
      max_cpu_percent: ${SIDECAR_MAX_CPU:-5.0}     # 5% CPU limit
      cpu_check_interval_seconds: 10.0             # Check every 10 seconds
      
      # Memory budget (megabytes)
      max_memory_mb: ${SIDECAR_MAX_MEMORY:-100}    # 100 MB limit
      memory_check_interval_seconds: 10.0          # Check every 10 seconds
      
      # Actions when budget exceeded
      on_cpu_exceeded:
        action: disable_profiling    # Options: log, disable_profiling, disable_all
        log_warning: true
      
      on_memory_exceeded:
        action: clear_queue          # Options: log, clear_queue, disable_all
        log_warning: true
    
    # â”€â”€ Structured Logging â”€â”€
    # JSON-only logging with correlation IDs
    logging:
      enabled: true
      format: json                   # Options: json, text (json REQUIRED)
      level: ${SIDECAR_LOG_LEVEL:-INFO}  # DEBUG, INFO, WARNING, ERROR
      
      # Correlation tracking
      correlation:
        track_run_id: true           # Track test run ID
        track_test_id: true          # Track test case ID
        track_session_id: true       # Track session ID
      
      # Log sampling (reduce log volume)
      sampling:
        enabled: true
        sample_rate: 0.1             # Log 10% of events
    
    # â”€â”€ Health & Readiness Endpoints â”€â”€
    # HTTP endpoints for health monitoring (Kubernetes-compatible)
    health:
      enabled: true
      bind_address: "0.0.0.0"        # Bind to all interfaces
      port: ${SIDECAR_HEALTH_PORT:-9090}  # Health endpoint port
      
      # Endpoints
      endpoints:
        health: /health              # Health check (returns 200/503)
        ready: /ready                # Readiness probe (returns 200/503)
        metrics: /metrics            # Prometheus metrics
        config: /sidecar/config/reload  # Config reload (POST)
      
      # Health check criteria
      criteria:
        queue_utilization: 0.95      # Degraded if queue > 95%
        error_rate: 0.1              # Degraded if errors > 10%
        cpu_budget: true             # Degraded if CPU over budget
        memory_budget: true          # Degraded if memory over budget
      
      # Readiness criteria (stricter than health)
      readiness:
        queue_utilization: 0.9       # Not ready if queue > 90%
        required_enabled: true       # Not ready if disabled
    
    # â”€â”€ Metrics Export â”€â”€
    # Prometheus-compatible metrics
    metrics:
      enabled: true
      format: prometheus             # Options: prometheus, json
      
      # Exported metrics (all counters, gauges, histograms)
      include:
        - sidecar.*.success          # Success counters
        - sidecar.*.errors           # Error counters
        - sidecar.*.duration_ms      # Duration histograms
        - sidecar.events_*           # Event metrics
        - sidecar.queue_*            # Queue metrics
        - sidecar.cpu_usage          # CPU gauge
        - sidecar.memory_usage       # Memory gauge
        - sidecar.profiling_*        # Profiling metrics
      
      # Metric labels
      labels:
        environment: ${ENVIRONMENT:-test}
        version: ${APP_VERSION:-v1.0.0}
        product: ${PRODUCT_NAME:-CrossBridgeApp}
    
    # â”€â”€ Configuration Reload â”€â”€
    # Reload config without restarting process
    config_reload:
      enabled: true
      endpoint: /sidecar/config/reload  # POST endpoint
      validation: true                   # Validate before applying
      backup_current: true               # Backup current config
    
    # â”€â”€ Profiling Integration â”€â”€
    profiling:
      enabled: true
      sampling_interval_seconds: 1.0     # Sample every second
      
      # Auto-disable profiling when CPU budget exceeded
      auto_disable_on_budget: true
      
      # Deep profiling (DEBUG ONLY - high overhead)
      deep_profiling:
        enabled: false
        duration_seconds: 30             # Auto-disable after 30s
        sample_interval_ms: 100          # Sample every 100ms
    
    # â”€â”€ Storage & Persistence â”€â”€
    storage:
      enabled: false                     # Disabled by default
      backend: none                      # Options: none, local, postgres
      
      # Local file storage
      local:
        path: .crossbridge/sidecar/events
        format: jsonl
        rotation:
          max_size_mb: 100
          max_files: 10
      
      # PostgreSQL storage (uses main DB connection)
      postgres:
        schema: sidecar_events
        table: events
        batch_insert_size: 1000


  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # AI TRANSFORMATION VALIDATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Validate AI-generated code changes with confidence scoring and human review
  # Automatically enabled during migration mode with optimal defaults
  
  ai_transformation:
    # Enable/disable AI transformation validation (DEFAULT: auto-enabled in migration mode)
    enabled: ${AI_TRANSFORM_ENABLED:-auto}  # Options: true, false, auto
    
    # Storage configuration
    storage:
      # Directory for transformation JSON files
      directory: ${AI_TRANSFORM_STORAGE:-.crossbridge/transformations}
      
      # Backup before applying transformations
      backup_enabled: true
      backup_directory: .crossbridge/transformations/backups
    
    # â”€â”€ Confidence Scoring â”€â”€
    # Multi-signal confidence computation for AI-generated code
    confidence:
      # Minimum confidence threshold for auto-apply (0.0-1.0)
      # Transformations below this threshold REQUIRE human review
      threshold: ${AI_CONFIDENCE_THRESHOLD:-0.8}
      
      # Confidence level boundaries
      levels:
        high: 0.8      # >= 0.8 = HIGH confidence (optional review)
        medium: 0.5    # 0.5-0.79 = MEDIUM confidence (review required)
        # < 0.5 = LOW confidence (review required)
      
      # Signal weights for confidence computation
      signals:
        model_confidence:
          enabled: true
          weight: 1.0              # Base multiplier
        
        diff_size:
          enabled: true
          # Penalties based on lines changed
          small_threshold: 20      # <= 20 lines: no penalty
          medium_threshold: 50     # 21-50 lines: -0.1
          large_threshold: 100     # 51-100 lines: -0.2
          very_large_penalty: -0.3 # > 100 lines: -0.3
        
        rule_violations:
          enabled: true
          penalty_per_violation: -0.1
          max_penalty: -0.3
        
        similarity_to_existing:
          enabled: true
          low_threshold: 0.6       # < 0.6: -0.2 penalty
          medium_threshold: 0.8    # < 0.8: -0.1 penalty
        
        syntax_validation:
          enabled: true
          penalty: -0.4            # Invalid syntax penalty
        
        test_coverage:
          enabled: true
          penalty: -0.2            # Coverage loss penalty
    
    # â”€â”€ Review Workflow â”€â”€
    # Human review process for low-confidence transformations
    review:
      # Require reviewer email for approvals/rejections
      require_reviewer: true
      
      # Require comments when rejecting
      require_rejection_reason: true
      
      # Allow re-review after rejection
      allow_rereview: false
      
      # Auto-expire pending reviews after N days
      expire_pending_days: 30
    
    # â”€â”€ Apply & Rollback â”€â”€
    # Configuration for applying and reverting transformations
    apply:
      # Create git commit when applying (if in git repo)
      git_commit: ${AI_TRANSFORM_GIT_COMMIT:-true}
      git_commit_prefix: "AI Transform:"
      
      # Verify syntax before applying
      verify_syntax: true
      
      # Run linting before applying
      run_linting: false
      linting_command: "flake8"
      
      # Run tests before finalizing apply
      run_tests: false
      test_command: "pytest"
    
    rollback:
      # Maximum rollback history to keep
      max_history: 10
      
      # Require confirmation for rollback
      require_confirmation: true
      
      # Create git commit when rolling back
      git_commit: true
      git_commit_prefix: "Rollback AI Transform:"
    
    # â”€â”€ Audit & Compliance â”€â”€
    # Tracking and logging for compliance requirements
    audit:
      # Enable comprehensive audit trail
      enabled: true
      
      # Hash prompts for privacy (store hash, not full prompt)
      hash_prompts: true
      
      # Log all transformation events
      log_all_events: true
      
      # Export audit logs to separate file
      export_logs: true
      export_path: .crossbridge/transformations/audit.jsonl
    
    # â”€â”€ CLI Defaults â”€â”€
    # Default values for CLI commands
    cli:
      # Default output format (table, detailed, json)
      default_format: table
      
      # Show diffs by default in 'show' command
      show_diff_default: false
      
      # Auto-apply after approval by default
      auto_apply_default: false
    
    # â”€â”€ Migration Mode Auto-Configuration â”€â”€
    # When crossbridge.mode = 'migration', these settings override above
    migration_overrides:
      enabled: true                    # Always enable in migration mode
      confidence_threshold: 0.85       # Higher threshold for migrations
      review_require_reviewer: true    # Require reviewer
      apply_git_commit: true          # Always commit
      apply_verify_syntax: true       # Always verify
      audit_enabled: true             # Always audit


  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # API CHANGE INTELLIGENCE
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Automatically enabled during migration for API test impact analysis
  
  api_change:
    enabled: false  # Set to true to enable API change intelligence
    
    # Spec source configuration
    spec_source:
      type: file  # Options: file, url, git
      current: specs/openapi.yaml
      previous: specs/openapi_prev.yaml
      
      # For URL-based specs:
      # type: url
      # current: https://api.example.com/v2/openapi.yaml
      # previous: https://api.example.com/v1/openapi.yaml
      # auth:
      #   type: bearer  # or 'basic'
      #   token: ${API_TOKEN}
      
      # For Git-based specs:
      # type: git
      # repository: https://github.com/example/api-specs.git
      # current_branch: main
      # previous_branch: release-1.0
      # spec_path: specs/openapi.yaml
    
    # Intelligence configuration
    intelligence:
      mode: hybrid  # Options: rules, hybrid, ai-only
      
      rules:
        enabled: true  # Rule-based intelligence (no AI required)
        
      ai:
        enabled: false  # Optional AI enhancement
        provider: openai  # Options: openai, anthropic
        model: gpt-4.1-mini  # or claude-3-5-sonnet-20240620
        api_key: ${OPENAI_API_KEY}  # Use environment variable
        max_tokens_per_month: 100000
        cost_limit_usd: 10.0
        max_retries: 3
        retry_backoff: 2
    
    # Impact analysis configuration
    impact_analysis:
      enabled: true
      test_directories:
        - tests/
        - test/
        - src/test/
      framework: pytest  # Options: pytest, robot, selenium, playwright, cypress, jest
      
      # Custom test-to-endpoint mappings
      custom_mappings:
        "GET /api/users":
          - test_file: tests/api/test_users.py
            test_name: test_get_users
        "POST /api/orders":
          - test_file: tests/api/test_orders.py
            test_name: test_create_order
      
      coverage_file: coverage/api-coverage.json
      min_confidence: 0.5
    
    # CI/CD integration
    ci_integration:
      enabled: true
      min_confidence: 0.5
      max_tests: 100
      frameworks:
        - pytest
        - robot
      exclude_patterns:
        - "**/integration/**"
        - "**/*slow*.py"
    
    # Alert configuration
    alerts:
      enabled: true
      
      # Email alerts
      email:
        enabled: false
        smtp_host: smtp.gmail.com
        smtp_port: 587
        smtp_user: alerts@example.com
        smtp_password: ${SMTP_PASSWORD}
        use_tls: true
        from_email: crossbridge@example.com
        to_emails:
          - qa-team@example.com
        subject_prefix: "[CrossBridge API Alert]"
        min_severity: high
        max_retries: 3
        retry_backoff: 2
      
      # Slack alerts
      slack:
        enabled: false
        webhook_url: ${SLACK_WEBHOOK_URL}
        channel: "#api-alerts"
        username: "CrossBridge AI"
        icon_emoji: ":robot_face:"
        mention_users:
          - U12345678
        min_severity: critical
        max_retries: 3
        retry_backoff: 2
      
      # Confluence alerts
      confluence:
        enabled: false
        url: https://your-domain.atlassian.net
        username: your-email@example.com
        auth_token: ${CONFLUENCE_TOKEN}
        space_key: API
        parent_page_id: 123456
        page_title_prefix: "API Change Alert"
        update_mode: create  # 'create' or 'update'
        max_retries: 3
        retry_backoff: 2
        min_severity: high
      
      # Microsoft Teams (planned)
      # teams:
      #   enabled: false
      #   webhook_url: ${TEAMS_WEBHOOK_URL}
    
    # Documentation generation
    documentation:
      enabled: true
      output_dir: docs/api-changes
      
      formats:
        markdown:
          enabled: true
          mode: incremental
          include_tests: true
          include_risk_badges: true
    
    # Grafana observability
    grafana:
      enabled: false
      dashboard_path: grafana/dashboards/api_change_intelligence.json
      datasource: postgresql
      refresh_interval: 30s

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # SEMANTIC SEARCH & TEST INTELLIGENCE
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Unified configuration for:
  # - Test normalization to UnifiedTestMemory format
  # - AST/structural signal extraction
  # - Vector embeddings and semantic similarity search
  # - Intelligent test discovery and recommendations
  semantic_search:
    # Enable/disable semantic search (auto = enable in migration mode)
    enabled: auto
    
    # â”€â”€ Test Normalization & AST Extraction â”€â”€
    # Automatic normalization to UnifiedTestMemory during test execution
    normalization:
      auto_normalize: true              # Auto-normalize tests to UnifiedTestMemory
      extract_structural_signals: true  # Extract imports, functions, assertions via AST
      extract_ui_interactions: true     # Extract UI commands (cy.click, page.goto, etc.)
      extract_api_calls: true           # Extract API endpoints and HTTP methods
      
      # Supported frameworks (all enabled by default)
      frameworks:
        cypress: true
        playwright: true
        robot: true
        pytest: true
        junit: true
        testng: true
        restassured: true
        selenium_java: true
        selenium_python: true
        cucumber: true
        behave: true
        specflow: true
    
    # â”€â”€ Embedding Provider Configuration â”€â”€
    # Embedding provider: openai, anthropic, local
    provider_type: openai
    
    # OpenAI configuration (text-embedding-3-large/small)
    openai:
      api_key: ${OPENAI_API_KEY}  # Required for OpenAI
      model: text-embedding-3-large  # 3072 dimensions, higher quality
      # model: text-embedding-3-small  # 1536 dimensions, faster/cheaper
      dimensions: 3072  # Match model dimensions
    
    # Anthropic configuration (Voyage AI)
    anthropic:
      api_key: ${ANTHROPIC_API_KEY}  # Required for Anthropic
      model: voyage-large-2  # 1536 dimensions
    
    # Local embedding configuration (sentence-transformers)
    local:
      model: all-MiniLM-L6-v2  # Fast, 384 dimensions
      device: cpu  # cpu or cuda
    
    # Search configuration
    search:
      max_tokens: 8000  # Maximum tokens for embedding text
      min_similarity_score: 0.7  # Minimum cosine similarity (0-1)
      default_top_k: 10  # Default number of results
      api_timeout: 30  # API timeout in seconds
      retry_attempts: 3  # Retry failed API calls
      batch_size: 100  # Batch size for bulk indexing
    
    # Vector store configuration
    vector_store:
      type: pgvector  # Currently only pgvector supported
      # Connection string from database.connection_string above
      index_type: ivfflat  # pgvector index type
      index_lists: 100  # Number of IVFFlat lists (tune based on data size)
      create_index_threshold: 1000  # Auto-create index after N entities
    
    # â”€â”€ Ingestion & Lifecycle â”€â”€
    ingestion:
      auto_ingest_on_discovery: true # Automatically ingest after test discovery
      update_on_change: true         # Re-embed when test code changes
      ttl_days: 90                   # Delete records older than N days (0 = never)
      cleanup_on_startup: false      # Clean old records on startup
    
    # â”€â”€ Migration Mode Overrides â”€â”€
    migration_overrides:
      enabled: true  # Always enable in migration mode
      provider_type: openai  # Preferred provider for migration
      model: text-embedding-3-large  # Best quality for migration analysis
      max_tokens: 8000
      min_similarity_score: 0.6  # Lower threshold for migration discovery
    
    # â”€â”€ Advanced Features â”€â”€
    # Runtime analysis, AI enhancement, profiling
    # AST augmentation for enhanced code structure understanding
    ast_augmentation:
      enabled: true  # Append AST summaries to embeddings
      languages:
        python: true  # Python stdlib ast
        java: true  # Pattern matching (JavaParser in production)
        javascript: true  # Pattern matching (tree-sitter in production)
      extract_classes: true
      extract_methods: true
      extract_imports: true
      extract_assertions: true
      extract_control_flow: true  # if/loop/try counts
      extract_decorators: true  # @pytest.mark, @Test, etc.
    
    # FAISS backend (alternative to pgvector for local/high-performance)
    faiss:
      enabled: false  # Set true to use FAISS instead of pgvector
      index_type: flat  # flat (exact), ivf (approximate), hnsw (graph-based)
      metric: cosine  # cosine, l2, ip (inner product)
      n_lists: 100  # IVF: number of clusters
      n_probe: 10  # IVF: clusters to search
      persist_path: ./data/faiss_index  # Where to save index
      auto_persist: true  # Save after each batch
    
    # Graph-based similarity (relationship-aware scoring)
    graph_similarity:
      enabled: true  # Enhance results with graph overlap
      semantic_weight: 0.7  # Weight for semantic similarity
      graph_weight: 0.3  # Weight for graph overlap
      build_test_graph: true  # Build test relationship graph
      edge_types:
        uses_file: true  # test -> file relationships
        calls_method: true  # test -> method relationships
        imports_module: true  # test -> module relationships
        occurs_in_test: true  # failure -> test relationships
    
    # Confidence calibration (trust scores for results)
    confidence:
      enabled: true  # Return confidence with every result
      sample_threshold: 30  # Full confidence at N samples
      min_confidence: 0.1  # Filter results below this
      enable_multi_signal: true  # Use text + AST + graph agreement
      show_reasons: true  # Include confidence reasons in results
      confidence_levels:
        high: 0.8  # High confidence >= 0.8
        medium: 0.6  # Medium confidence >= 0.6
        low: 0.0  # Low confidence < 0.6

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # UNIFIED PERFORMANCE PROFILING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Consolidated profiling for all use cases:
  # - Runtime profiling (semantic search, embeddings, vector stores)
  # - Test execution profiling (test lifecycle, commands, HTTP)
  # - System profiling (CPU, memory, threads, GC)
  # - Benchmarking (adapter comparison)
  #
  # Safe for production, zero cost when disabled
  profiling:
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RUNTIME PROFILING (default)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Profiles internal CrossBridge operations
    runtime:
      enabled: false
      type: runtime  # runtime | test_execution | system | benchmark
      mode: sampling  # sampling | full
      level: basic  # basic (timing) | detailed (timing + memory)
      
      # Targets to profile (empty = all)
      targets:
        - semantic_search
        - embedding_provider
        - vector_store
        - pgvector_store
        - faiss_store
      
      # Thresholds
      thresholds:
        slow_call_ms: 500  # Alert if call > 500ms
        memory_mb: 50  # Alert if memory > 50MB
      
      # Sampling
      sample_rate: 0.1  # Profile 10% of requests
      
      # Output
      output:
        type: log  # log | file | prometheus | none
        path: ./data/profiling/runtime.jsonl
      
      # Safety limits
      max_records_per_minute: 100
      include_metadata: true
      include_stack_trace: false
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TEST EXECUTION PROFILING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Profiles test lifecycle, driver commands, HTTP requests
    # Replaces legacy profiling system
    test_execution:
      enabled: false
      type: test_execution
      mode: full  # Usually full for test profiling
      level: basic
      
      # What to capture
      capture:
        test_lifecycle: true  # Test start/end
        commands: true  # Driver commands (Selenium, Playwright, etc.)
        http: true  # HTTP requests
        assertions: false  # Individual assertions (can be noisy)
      
      # Thresholds (only emit if exceeded)
      thresholds:
        slow_call_ms: 100  # Lower threshold for test commands
        memory_mb: 50
      
      # Output (can use database for structured storage)
      output:
        type: database  # log | file | database | none
        database_path: ./data/profiling/test_execution.db
      
      # Safety limits
      max_records_per_minute: 1000  # Higher for test execution
      include_metadata: true
      include_stack_trace: false
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SYSTEM PROFILING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # System-level monitoring (CPU, memory, threads, GC)
    # Replaces sidecar LightweightProfiler
    system:
      enabled: false
      type: system
      level: system  # Use system level for system profiling
      
      # What to monitor
      monitor:
        cpu: true
        memory: true
        threads: true
        gc: true  # Garbage collection
      
      # Sampling (background monitoring)
      sampling_interval: 1.0  # Sample every 1 second
      max_snapshots: 1000  # Keep last 1000 snapshots
      
      # Thresholds for alerts
      thresholds:
        cpu_percent: 80.0  # Alert if CPU > 80%
        memory_mb: 500  # Alert if memory increase > 500MB
      
      # Output
      output:
        type: log  # log | file | prometheus
        path: ./data/profiling/system.jsonl
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # BENCHMARKING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Adapter performance comparison
    # Replaces PerformanceBenchmark
    benchmarking:
      enabled: false
      type: benchmark
      
      # Benchmark configuration
      iterations: 10  # Iterations per benchmark
      compare_baselines: true  # Compare against baselines
      baseline_adapters:  # Baseline adapters for comparison
        - selenium_python
        - playwright_python
      
      # Output
      output:
        type: file  # file | log
        path: ./data/profiling/benchmark_results.json

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXECUTION ORCHESTRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Intelligent test execution orchestration
# Determines WHAT, WHEN, and HOW to run tests (delegates actual execution to frameworks)
execution:
  enabled: true
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # STRATEGY CONFIGURATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  strategies:
    # Smoke strategy - fast signal tests
    smoke:
      enabled: true
      tags: ["smoke", "sanity", "critical", "p0"]
      max_duration_minutes: 10
      always_include_critical: true
    
    # Impacted strategy - tests affected by code changes
    impacted:
      enabled: true
      
      # Sources for impact analysis
      sources:
        git_diff: true           # Analyze changed files
        coverage_mapping: true   # Use code coverage data
        semantic_analysis: true  # Use semantic engine (if available)
      
      # Fallback if no tests selected
      fallback_strategy: smoke
      min_tests: 5  # Minimum tests to run
      
      # Always include certain tests
      always_include:
        critical: true
        recent_failures: true
        flaky_prevention: false  # Don't auto-include flaky tests
      
      # Semantic similarity threshold (if using semantic engine)
      semantic_threshold: 0.7
    
    # Risk-based strategy - historical risk analysis
    risk:
      enabled: true
      
      # Risk scoring weights
      weights:
        failure_rate: 0.4        # Historical failures
        code_churn: 0.2          # Changes in covered code
        criticality: 0.3         # Business criticality
        flakiness_penalty: -0.1  # Penalize flaky tests
      
      # Risk score thresholds
      min_risk_score: 0.3
      
      # Budget limits
      default_max_tests: 100
      default_max_duration_minutes: 60
    
    # Full strategy - all tests
    full:
      enabled: true
      parallel: true
      max_duration_minutes: 180  # 3 hours limit
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FRAMEWORK ADAPTERS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  adapters:
    testng:
      enabled: true
      build_tool: mvn  # mvn or gradle
      suite_xml_path: target/crossbridge-suite.xml
      parallel_methods: 4
      report_dir: target/surefire-reports
    
    junit:
      enabled: true
      build_tool: mvn  # mvn or gradle
      parallel_enabled: true
      report_dir: target/surefire-reports
    
    restassured:
      enabled: true
      build_tool: mvn  # mvn or gradle
      test_framework: testng  # testng or junit
      parallel_tests: true
      report_dir: target/surefire-reports
    
    robot:
      enabled: true
      use_pabot: true  # Use pabot for parallel execution
      pabot_processes: 4
      output_dir: robot-results
      log_level: INFO
    
    pytest:
      enabled: true
      use_xdist: true  # Use pytest-xdist for parallel execution
      xdist_workers: 4
      junit_xml: pytest-results.xml
      html_report: pytest-report.html
    
    behave:
      enabled: true
      parallel_processes: 4
      output_format: json
      results_file: behave-results.json
    
    cypress:
      enabled: true
      parallel: true
      record: false  # Record to Cypress Dashboard
      browser: chrome
      results_dir: cypress/results
    
    playwright:
      enabled: true
      parallel: true
      workers: 4
      reporter: json
      results_dir: playwright-report
    
    cucumber:
      enabled: true
      parallel_enabled: true
      output_format: json
      report_file: target/cucumber-report.json
    
    specflow:
      enabled: true
      dotnet_test: true
      logger: trx
      results_dir: TestResults
    
    nunit:
      enabled: true
      dotnet_test: true
      logger: nunit
      results_dir: TestResults
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # EXECUTION SETTINGS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  settings:
    # Default strategy per environment
    default_strategy:
      dev: smoke
      qa: impacted
      staging: risk
      prod: risk
    
    # Parallelization
    parallel:
      enabled: true
      max_workers: 4
      per_framework: true  # Framework-specific parallel settings
    
    # Timeouts
    timeouts:
      default_test_timeout: 300  # 5 minutes per test
      default_suite_timeout: 3600  # 1 hour per suite
      global_timeout: 7200  # 2 hours absolute max
    
    # Retries
    retries:
      enabled: true
      max_retries: 1
      retry_on:
        - timeout
        - infrastructure_failure
      never_retry:
        - assertion_error
        - explicit_failure
    
    # CI/CD mode optimizations
    ci_mode:
      verbose_logging: true
      fail_fast: false
      archive_results: true
      parallel_aggressive: true
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # RESULT HANDLING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  results:
    # Store results in database
    store_results: true
    database: postgresql  # Use main database
    
    # Result retention
    retention_days: 90
    
    # Notifications (placeholder for future)
    notifications:
      enabled: false
      channels: []  # slack, email, etc.
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # INTEGRATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  integration:
    # Git integration for impact analysis
    git:
      enabled: true
      default_base_branch: main
      fetch_depth: 100  # Number of commits to analyze
    
    # Memory integration for semantic analysis
    memory:
      enabled: true
      use_semantic_engine: true
    
    # Coverage integration
    coverage:
      enabled: true
      sources:
        - jacoco  # Java
        - coverage.py  # Python
        - nyc  # JavaScript
    
    # Flaky detection integration
    flaky_detection:
      enabled: true
      exclude_flaky_by_default: true
      flaky_threshold: 0.2  # 20% failure rate


# ============================================================================
# SIDECAR INTEGRATION EXAMPLES
# ============================================================================
# CrossBridge can run as a sidecar container alongside your test execution,
# providing continuous intelligence without requiring test migration.
#
# Supported Frameworks:
# - Java (Selenium, RestAssured, TestNG, JUnit)
# - Robot Framework (Python, SeleniumLibrary, RequestsLibrary)
# - pytest, Cypress, Playwright, and 8+ more
#
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Example 1: Java Selenium BDD (TestNG + Cucumber)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# Prerequisites:
# âœ… Java 11+ installed
# âœ… Maven or Gradle project
# âœ… Selenium WebDriver configured
# âœ… TestNG or JUnit with Cucumber
#
# Integration Steps:
#
# 1. Add CrossBridge Java Listener to testng.xml:
#    <listeners>
#      <listener class-name="com.crossbridge.CrossBridgeListener"/>
#    </listeners>
#
# 2. OR add via JUnit annotation:
#    @RunWith(CrossBridgeRunner.class)
#    public class MyTests extends TestBase { ... }
#
# 3. Set system properties (pom.xml or gradle.properties):
#    <systemPropertyVariables>
#      <crossbridge.enabled>true</crossbridge.enabled>
#      <crossbridge.db.host>10.55.12.99</crossbridge.db.host>
#      <crossbridge.db.port>5432</crossbridge.db.port>
#      <crossbridge.db.name>crossbridge</crossbridge.db.name>
#      <crossbridge.product.name>${project.artifactId}</crossbridge.product.name>
#      <crossbridge.application.version>${project.version}</crossbridge.application.version>
#      <crossbridge.environment>${env}</crossbridge.environment>
#    </systemPropertyVariables>
#
# 4. Run tests normally - CrossBridge observes automatically:
#    mvn clean test -Dcrossbridge.enabled=true
#    gradle test --info
#
# Maven Docker Command:
#   docker run --rm \
#     -v $(pwd):/workspace \
#     -v $(pwd)/crossbridge-data:/data \
#     --network bridge \
#     -e CROSSBRIDGE_DB_HOST=10.55.12.99 \
#     -e PRODUCT_NAME=MyJavaApp \
#     -e APP_VERSION=v2.0.0 \
#     maven:3.9-eclipse-temurin-11 \
#     mvn test -Dcrossbridge.enabled=true
#
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Example 2: Robot Framework (Python + Requests + Selenium)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# Prerequisites:
# âœ… Python 3.9+ installed
# âœ… Robot Framework: pip install robotframework
# âœ… RequestsLibrary: pip install robotframework-requests
# âœ… SeleniumLibrary: pip install robotframework-seleniumlibrary (optional)
#
# Integration Steps:
#
# 1. Add CrossBridge listener to robot command:
#    robot --listener crossbridge.hooks.robot_hooks.CrossBridgeListener tests/
#
# 2. OR add to robot.toml / robot.yaml:
#    [robot]
#    listeners = [\"crossbridge.hooks.robot_hooks.CrossBridgeListener\"]
#
# 3. OR add to Robot file:
#    *** Settings ***
#    Library    crossbridge.hooks.robot_hooks.CrossBridgeListener
#
# 4. Set environment variables:
#    export CROSSBRIDGE_HOOKS_ENABLED=true
#    export CROSSBRIDGE_DB_HOST=10.55.12.99
#    export CROSSBRIDGE_DB_PORT=5432
#    export CROSSBRIDGE_DB_NAME=crossbridge
#    export PRODUCT_NAME=MyRobotApp
#    export APP_VERSION=v2.0.0
#    export ENVIRONMENT=test
#
# 5. Run tests normally - CrossBridge observes automatically:
#    robot --listener crossbridge.hooks.robot_hooks.CrossBridgeListener \
#          --variable CROSSBRIDGE_ENABLED:true \
#          tests/
#
# Docker Command:
#   docker run --rm \
#     -v $(pwd):/workspace \
#     -v $(pwd)/crossbridge-data:/data \
#     --network bridge \
#     -e CROSSBRIDGE_HOOKS_ENABLED=true \
#     -e CROSSBRIDGE_DB_HOST=10.55.12.99 \
#     -e PRODUCT_NAME=MyRobotApp \
#     -e APP_VERSION=v2.0.0 \
#     python:3.11-slim \
#     bash -c \"pip install robotframework robotframework-requests robotframework-seleniumlibrary && \
#              robot --listener crossbridge.hooks.robot_hooks.CrossBridgeListener tests/\"
#
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Docker Compose Sidecar Pattern
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# For both frameworks, use docker-compose for easier orchestration:
#
# services:
#   crossbridge-observer:
#     image: crossbridge/crossbridge:0.2.0
#     environment:
#       - CROSSBRIDGE_MODE=observer
#       - CROSSBRIDGE_DB_HOST=10.55.12.99
#       - PRODUCT_NAME=MyApp
#       - APP_VERSION=v2.0.0
#     volumes:
#       - ./crossbridge-data:/data
#     network_mode: bridge
#     restart: unless-stopped
#
#   java-tests:
#     image: maven:3.9-eclipse-temurin-11
#     depends_on:
#       - crossbridge-observer
#     environment:
#       - crossbridge.enabled=true
#       - crossbridge.db.host=10.55.12.99
#     volumes:
#       - ./java-project:/workspace
#     working_dir: /workspace
#     command: mvn test
#
#   robot-tests:
#     image: python:3.11-slim
#     depends_on:
#       - crossbridge-observer
#     environment:
#       - CROSSBRIDGE_HOOKS_ENABLED=true
#       - CROSSBRIDGE_DB_HOST=10.55.12.99
#     volumes:
#       - ./robot-project:/workspace
#     working_dir: /workspace
#     command: bash -c \"pip install robotframework robotframework-requests && \
#              robot --listener crossbridge.hooks.robot_hooks.CrossBridgeListener tests/\"
#
# Run: docker-compose up --abort-on-container-exit
#
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Verification
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# 1. Check CrossBridge logs:
#    tail -f crossbridge-data/logs/crossbridge.log
#
# 2. Verify database entries:
#    psql -h 10.55.12.99 -U postgres -d crossbridge \
#         -c \"SELECT * FROM test_executions ORDER BY created_at DESC LIMIT 10;\"
#
# 3. Check health endpoint (if enabled):
#    curl http://localhost:9090/health
#    curl http://localhost:9090/ready
#    curl http://localhost:9090/metrics
#
# 4. View Grafana dashboards (if configured):
#    http://localhost:3000
#
# ============================================================================
