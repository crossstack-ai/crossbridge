#!/usr/bin/env bash
#
# CrossBridge Log Parser CLI
# Auto-detects log format and sends to sidecar API for parsing
#
# Usage:
#   ./crossbridge-log <log-file>
#   ./crossbridge-log output.xml
#   ./crossbridge-log cypress-results.json
#   ./crossbridge-log playwright-trace.json
#

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check required dependencies
check_dependencies() {
    local missing_deps=()
    
    if ! command -v curl &> /dev/null; then
        missing_deps+=("curl")
    fi
    
    if ! command -v jq &> /dev/null; then
        missing_deps+=("jq")
    fi
    
    if [ ${#missing_deps[@]} -gt 0 ]; then
        echo -e "${RED}Error: Missing required dependencies: ${missing_deps[*]}${NC}" >&2
        echo "" >&2
        echo "Installation instructions:" >&2
        echo "  â€¢ curl: Usually pre-installed on most systems" >&2
        echo "  â€¢ jq: JSON processor" >&2
        echo "    - Windows: choco install jq  OR  download from https://jqlang.github.io/jq/download/" >&2
        echo "    - macOS: brew install jq" >&2
        echo "    - Linux: sudo apt-get install jq  OR  sudo yum install jq" >&2
        exit 1
    fi
}

check_dependencies

# Configuration (use standard CrossBridge environment variables)
SIDECAR_HOST="${CROSSBRIDGE_SIDECAR_HOST:-localhost}"
SIDECAR_PORT="${CROSSBRIDGE_SIDECAR_PORT:-8765}"
SIDECAR_URL="http://${SIDECAR_HOST}:${SIDECAR_PORT}"

# Parse command-line arguments
OUTPUT_FILE=""
FILTER_TEST_ID=""
FILTER_TEST_NAME=""
FILTER_TIME_FROM=""
FILTER_TIME_TO=""
FILTER_STATUS=""
FILTER_ERROR_CODE=""
FILTER_PATTERN=""
ENABLE_ANALYSIS=true  # Enable automatic intelligence analysis
SHOW_HELP=false
LOG_FILE=""
APP_LOGS=""  # Application logs for correlation
ENABLE_AI=false  # Enable AI-enhanced analysis (requires license)

show_usage() {
    echo "CrossBridge Log Parser - Universal log parsing for all frameworks"
    echo ""
    echo "Usage: $0 <log-file> [OPTIONS]"
    echo ""
    echo "Examples:"
    echo "  $0 output.xml                                    # Robot Framework"
    echo "  $0 cypress/results.json                          # Cypress"
    echo "  $0 output.xml --output results.json              # Save to file"
    echo "  $0 output.xml --app-logs app.log                 # Correlate with application logs"
    echo "  $0 output.xml --enable-ai                        # Enable AI-enhanced analysis"
    echo "  $0 output.xml --test-name 'Login*'               # Filter by test name"
    echo "  $0 output.xml --test-id 's1-s1-t1'               # Filter by test ID"
    echo "  $0 output.xml --status FAIL                      # Filter failed tests only"
    echo "  $0 output.xml --time-from '2026-02-05T10:00:00'  # Tests after time"
    echo "  $0 output.xml --time-to '2026-02-05T12:00:00'    # Tests before time"
    echo ""
    echo "Supported Frameworks:"
    echo "  - Robot Framework (output.xml, robot*.xml)"
    echo "  - Cypress (cypress-results.json, *cypress*.json)"
    echo "  - Playwright (playwright-trace.json, trace*.json)"
    echo "  - Behave (behave-results.json, *behave*.json)"
    echo "  - Java Cucumber (*Steps.java, *StepDefinitions.java)"
    echo ""
    echo "Options:"
    echo "  -o, --output FILE          Save parsed results to FILE (JSON format)"
    echo "  -a, --app-logs FILE        Application logs for correlation (JSON format)"
    echo "  --enable-ai                Enable AI-enhanced analysis (requires license, incurs cost)"
    echo "  -t, --test-name PATTERN    Filter tests by name (supports wildcards)"
    echo "  -i, --test-id ID           Filter by specific test ID"
    echo "  -s, --status STATUS        Filter by status (PASS, FAIL, SKIP)"
    echo "  -e, --error-code CODE      Filter by error code in messages"
    echo "  -p, --pattern PATTERN      Filter by text pattern (case-insensitive)"
    echo "  --time-from DATETIME       Filter tests starting after DATETIME"
    echo "  --time-to DATETIME         Filter tests ending before DATETIME"
    echo "  --no-analyze               Disable automatic intelligence analysis"
    echo "  -h, --help                 Show this help message"
    echo ""
    echo "Automatic Intelligence Features (enabled by default):"
    echo "  â€¢ Failure Classification - PRODUCT_DEFECT, AUTOMATION_DEFECT, ENVIRONMENT_ISSUE, etc."
    echo "  â€¢ Signal Extraction - Timeout, assertion, locator errors"
    echo "  â€¢ Code Reference Resolution - Pinpoints test code location"
    echo "  â€¢ Root Cause Analysis - Explains why test failed"
    echo ""
    echo "Environment Variables:"
    echo "  CROSSBRIDGE_SIDECAR_HOST   - Sidecar API host (default: localhost)"
    echo "  CROSSBRIDGE_SIDECAR_PORT   - Sidecar API port (default: 8765)"
    echo ""
}

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            show_usage
            exit 0
            ;;
        -o|--output)
            OUTPUT_FILE="$2"
            shift 2
            ;;
        -a|--app-logs)
            APP_LOGS="$2"
            if [ ! -f "$APP_LOGS" ]; then
                echo -e "${RED}Error: Application log file not found: $APP_LOGS${NC}"
                exit 1
            fi
            shift 2
            ;;
        --enable-ai)
            ENABLE_AI=true
            shift
            ;;
        -t|--test-name)
            FILTER_TEST_NAME="$2"
            shift 2
            ;;
        -i|--test-id)
            FILTER_TEST_ID="$2"
            shift 2
            ;;
        -s|--status)
            FILTER_STATUS="$2"
            shift 2
            ;;
        -e|--error-code)
            FILTER_ERROR_CODE="$2"
            shift 2
            ;;
        -p|--pattern)
            FILTER_PATTERN="$2"
            shift 2
            ;;
        --time-from)
            FILTER_TIME_FROM="$2"
            shift 2
            ;;
        --time-to)
            FILTER_TIME_TO="$2"
            shift 2
            ;;
        -*)
            echo -e "${RED}Error: Unknown option: $1${NC}"
            echo ""
            show_usage
            exit 1
            ;;
        *)
            if [ -z "$LOG_FILE" ]; then
                LOG_FILE="$1"
            else
                echo -e "${RED}Error: Multiple log files specified${NC}"
                exit 1
            fi
            shift
            ;;
    esac
done

# Check if file argument provided
if [ -z "$LOG_FILE" ]; then
    echo -e "${RED}Error: No log file specified${NC}"
    echo ""
    show_usage
    exit 1
fi

# Check if file exists
if [ ! -f "$LOG_FILE" ]; then
    echo -e "${RED}Error: File not found: $LOG_FILE${NC}"
    exit 1
fi

# Auto-detect framework based on file name and content
detect_framework() {
    local file="$1"
    local basename=$(basename "$file")
    
    # Check by filename patterns
    case "$basename" in
        output.xml|robot*.xml)
            echo "robot"
            return
            ;;
        *cypress*.json|cypress-*.json)
            echo "cypress"
            return
            ;;
        *playwright*.json|trace*.json)
            echo "playwright"
            return
            ;;
        *behave*.json|*cucumber*.json)
            # Check content to distinguish
            if grep -q '"feature"' "$file" 2>/dev/null; then
                echo "behave"
            else
                echo "cypress"
            fi
            return
            ;;
        *Steps.java|*StepDefinitions.java|*StepDefs.java)
            echo "java"
            return
            ;;
    esac
    
    # Check by content
    if head -n 5 "$file" | grep -q '<robot' 2>/dev/null; then
        echo "robot"
        return
    elif head -n 5 "$file" | grep -q '"suites"' 2>/dev/null; then
        echo "cypress"
        return
    elif head -n 5 "$file" | grep -q '"entries"' 2>/dev/null; then
        echo "playwright"
        return
    elif head -n 5 "$file" | grep -q '"feature"' 2>/dev/null; then
        echo "behave"
        return
    elif grep -q '@Given\|@When\|@Then' "$file" 2>/dev/null; then
        echo "java"
        return
    fi
    
    # Default fallback
    echo "unknown"
}

# Check sidecar health
echo -e "${BLUE}ğŸ” Checking CrossBridge Sidecar API...${NC}"
if ! curl -s -f "${SIDECAR_URL}/health" > /dev/null 2>&1; then
    echo ""
    echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${RED}  âŒ CROSSBRIDGE SIDECAR API NOT REACHABLE${NC}"
    echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo -e "${YELLOW}Attempting to reach: ${NC}${SIDECAR_URL}"
    echo ""
    echo -e "${YELLOW}ğŸ”§ Troubleshooting Steps:${NC}"
    echo ""
    echo -e "${BLUE}1. Check if Sidecar is Running:${NC}"
    echo "   docker ps | grep crossbridge-sidecar"
    echo "   # Should show: 'Up' status (not 'Restarting')"
    echo ""
    echo -e "${BLUE}2. If Container is Restarting, Check Logs:${NC}"
    echo "   docker logs crossbridge-sidecar --tail 50"
    echo ""
    echo -e "${BLUE}3. Start Sidecar (if not running):${NC}"
    echo "   docker-compose up -d crossbridge-sidecar"
    echo "   # Or for local development:"
    echo "   python -m services.sidecar_api"
    echo ""
    echo -e "${BLUE}4. Verify Environment Variables:${NC}"
    echo "   Current configuration:"
    echo "   â€¢ CROSSBRIDGE_SIDECAR_HOST = ${SIDECAR_HOST}"
    echo "   â€¢ CROSSBRIDGE_SIDECAR_PORT = ${SIDECAR_PORT}"
    echo ""
    echo -e "${BLUE}5. Test Connection:${NC}"
    echo "   curl ${SIDECAR_URL}/health"
    echo "   # Expected: {\"status\":\"healthy\"}"
    echo ""
    echo -e "${YELLOW}ğŸ“– Documentation:${NC}"
    echo "   docs/cli/CROSSBRIDGE_LOG.md"
    echo "   docs/REMOTE_SIDECAR_README.md"
    echo ""
    echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    exit 1
fi

# Detect framework
FRAMEWORK=$(detect_framework "$LOG_FILE")

if [ "$FRAMEWORK" = "unknown" ]; then
    echo -e "${RED}Error: Could not detect log format${NC}"
    echo "Supported formats:"
    echo "  - Robot Framework (output.xml)"
    echo "  - Cypress (cypress-results.json)"
    echo "  - Playwright (playwright-trace.json)"
    echo "  - Behave (behave-results.json)"
    echo "  - Java Cucumber (*Steps.java)"
    exit 1
fi

echo -e "${GREEN}âœ“${NC} Detected framework: ${BLUE}${FRAMEWORK}${NC}"
echo -e "${BLUE}Parsing log file: ${LOG_FILE}${NC}"

# Show active filters
if [ -n "$FILTER_TEST_NAME" ] || [ -n "$FILTER_TEST_ID" ] || [ -n "$FILTER_STATUS" ] || [ -n "$FILTER_TIME_FROM" ] || [ -n "$FILTER_TIME_TO" ] || [ -n "$FILTER_ERROR_CODE" ] || [ -n "$FILTER_PATTERN" ]; then
    echo -e "${YELLOW}Active Filters:${NC}"
    [ -n "$FILTER_TEST_NAME" ] && echo "  â€¢ Test Name: $FILTER_TEST_NAME"
    [ -n "$FILTER_TEST_ID" ] && echo "  â€¢ Test ID: $FILTER_TEST_ID"
    [ -n "$FILTER_STATUS" ] && echo "  â€¢ Status: $FILTER_STATUS"
    [ -n "$FILTER_ERROR_CODE" ] && echo "  â€¢ Error Code: $FILTER_ERROR_CODE"
    [ -n "$FILTER_PATTERN" ] && echo "  â€¢ Pattern: $FILTER_PATTERN"
    [ -n "$FILTER_TIME_FROM" ] && echo "  â€¢ Time From: $FILTER_TIME_FROM"
    [ -n "$FILTER_TIME_TO" ] && echo "  â€¢ Time To: $FILTER_TIME_TO"
fi
echo ""

# Parse log file
RESPONSE=$(curl -s -X POST "${SIDECAR_URL}/parse/${FRAMEWORK}" \
    -H "Content-Type: application/octet-stream" \
    --data-binary "@${LOG_FILE}")

# Check if response is valid JSON
if ! echo "$RESPONSE" | jq empty 2>/dev/null; then
    echo -e "${RED}Error: Invalid response from sidecar${NC}"
    echo "$RESPONSE"
    exit 1
fi

# Check for errors
if echo "$RESPONSE" | jq -e '.detail' > /dev/null 2>&1; then
    ERROR_MSG=$(echo "$RESPONSE" | jq -r '.detail')
    echo -e "${RED}Error: ${ERROR_MSG}${NC}"
    exit 1
fi

# Enrich with execution intelligence (automatic analysis)
enrich_with_intelligence() {
    local data="$1"
    
    if [ "$ENABLE_ANALYSIS" != "true" ]; then
        echo "$data"
        return
    fi
    
    # Capture start time for duration tracking
    local ANALYSIS_START_TIME=$(date +%s)
    
    echo -e "${BLUE}Running intelligence analysis...${NC}" >&2
    
    # Show AI warning and get confirmation if AI is enabled
    if [ "$ENABLE_AI" = "true" ]; then
        # Get AI provider info from sidecar (with retry for new endpoint)
        local provider_info=$(curl -s -w "\n%{http_code}" "${SIDECAR_URL}/ai-provider-info" 2>&1)
        local http_code=$(echo "$provider_info" | tail -n1)
        local response_body=$(echo "$provider_info" | sed '$d')
        
        # Debug: Show what we got (if verbose)
        [ "$VERBOSE" = "true" ] && echo "[DEBUG] Provider info HTTP code: $http_code" >&2
        [ "$VERBOSE" = "true" ] && echo "[DEBUG] Provider info response: $response_body" >&2
        
        # Parse JSON response
        local ai_provider=""
        local ai_model=""
        local cost_per_1k=""
        local typical_cost=""
        
        # Check if endpoint exists and returned valid JSON
        if [ "$http_code" = "200" ] && echo "$response_body" | grep -q '"provider"'; then
            ai_provider=$(echo "$response_body" | grep -o '"provider":"[^"]*"' | cut -d'"' -f4)
            ai_model=$(echo "$response_body" | grep -o '"model":"[^"]*"' | cut -d'"' -f4 | grep -v "null")
            cost_per_1k=$(echo "$response_body" | grep -o '"cost_per_1k_tokens":[0-9.]*' | cut -d':' -f2)
            typical_cost=$(echo "$response_body" | grep -o '"typical_run_cost":"[^"]*"' | cut -d'"' -f4)
        else
            # Endpoint doesn't exist yet (old sidecar) or sidecar not running
            [ "$VERBOSE" = "true" ] && echo "[DEBUG] Provider info endpoint not available (HTTP $http_code), using fallback" >&2
            ai_provider="unknown"
        fi
        
        # Display banner based on provider type
        if [ "$ai_provider" = "selfhosted" ]; then
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            echo -e "${GREEN}ğŸ¤–  AI-ENHANCED ANALYSIS ENABLED${NC}" >&2
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            echo -e "${GREEN}Provider: Self-hosted (${ai_model})${NC}" >&2
            echo -e "${GREEN}Cost: No additional costs (local inference)${NC}" >&2
            echo -e "${GREEN}License: Not required for self-hosted AI${NC}" >&2
        elif [ "$ai_provider" = "openai" ] || [ "$ai_provider" = "anthropic" ]; then
            echo -e "${YELLOW}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            echo -e "${YELLOW}âš ï¸  AI-ENHANCED ANALYSIS ENABLED${NC}" >&2
            echo -e "${YELLOW}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            echo -e "${YELLOW}Provider: ${ai_provider^} (${ai_model})${NC}" >&2
            echo -e "${YELLOW}Using AI for log analysis will incur costs:${NC}" >&2
            echo -e "${YELLOW}  â€¢ Cost: ~\$${cost_per_1k} per 1000 tokens${NC}" >&2
            echo -e "${YELLOW}  â€¢ Typical analysis: ${typical_cost}${NC}" >&2
            echo -e "${YELLOW}  â€¢ Costs vary by log size and complexity${NC}" >&2
        else
            # Fallback for unknown/error/missing provider info
            # Will be auto-detected during actual analysis
            echo -e "${YELLOW}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            echo -e "${YELLOW}âš ï¸  AI-ENHANCED ANALYSIS ENABLED${NC}" >&2
            echo -e "${YELLOW}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            if [ "$ai_provider" = "error" ] || [ "$ai_provider" = "none" ] || [ -z "$ai_provider" ]; then
                echo -e "${YELLOW}Provider: Auto-detecting...${NC}" >&2
                echo -e "${YELLOW}(Costs may apply if using cloud providers)${NC}" >&2
            else
                echo -e "${YELLOW}Provider: ${ai_provider^}${NC}" >&2
                echo -e "${YELLOW}Using AI for log analysis may incur costs${NC}" >&2
            fi
        fi
        echo "" >&2
        echo -e "${BLUE}Checking AI configuration...${NC}" >&2
        
        # For self-hosted AI, show immediate confirmation with model details
        if [ "$ai_provider" = "selfhosted" ]; then
            local model_display="${ai_model:-unknown model}"
            echo -e "${GREEN}âœ… Detected cached AI provider: Self-Hosted [Model: ${model_display}]${NC}" >&2
            echo "" >&2
            echo -e "${BLUE}â„¹ï¸  Self-hosted AI detected - skipping license validation${NC}" >&2
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
        else
            # For cloud providers, validate license with sidecar
            local test_payload='{"data":{"tests":[]},"framework":"test","enable_ai":true}'
            local license_check=$(echo "$test_payload" | curl -s -X POST "${SIDECAR_URL}/analyze" \
                -H "Content-Type: application/json" --data-binary @- 2>&1)
            
            # Check if it's a license failure
            if echo "$license_check" | grep -q "AI License validation failed\|403"; then
                # Cloud provider requires license
                echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
                echo -e "${RED}âŒ AI License Validation Failed${NC}" >&2
                echo -e "${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
                echo -e "${RED}No valid AI license found or license expired.${NC}" >&2
                echo "" >&2
                echo -e "${YELLOW}To use AI features:${NC}" >&2
                echo -e "${YELLOW}  1. Configure AI settings: crossbridge test-creds --action cache-ai${NC}" >&2
                echo -e "${YELLOW}  2. For cloud providers: Obtain a valid license${NC}" >&2
                echo -e "${YELLOW}  3. For self-hosted: Cache your endpoint URL and model${NC}" >&2
                echo "" >&2
                echo -e "${BLUE}Continuing with standard analysis (no AI)...${NC}" >&2
                ENABLE_AI=false
            else
                # Cloud provider with valid license
                if [ "$ai_provider" = "openai" ]; then
                    echo -e "${GREEN}âœ… Detected cached AI provider: OpenAI [Model: ${ai_model:-gpt-3.5-turbo}]${NC}" >&2
                    echo "" >&2
                    echo -e "${GREEN}âœ“ License validated successfully${NC}" >&2
                elif [ "$ai_provider" = "anthropic" ]; then
                    echo -e "${GREEN}âœ… Detected cached AI provider: Anthropic [Model: ${ai_model:-claude-3-sonnet}]${NC}" >&2
                    echo "" >&2
                    echo -e "${GREEN}âœ“ License validated successfully${NC}" >&2
                else
                    echo -e "${GREEN}âœ… AI provider detected${NC}" >&2
                    echo "" >&2
                    echo -e "${GREEN}âœ“ License validated successfully${NC}" >&2
                fi
                echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
            fi
        fi
    fi
    
    # Choose endpoint based on whether app logs are provided
    local endpoint="/analyze"
    local payload
    
    if [ -n "$APP_LOGS" ]; then
        echo -e "${BLUE}Correlating with application logs...${NC}" >&2
        endpoint="/analyze/with-app-logs"
        
        # Build payload with app logs path and AI flag
        # Use stdin to avoid "Argument list too long" error with large data
        payload=$(echo "$data" | jq \
            --arg app_logs "$APP_LOGS" \
            --arg framework "$FRAMEWORK" \
            --arg workspace_root "$(pwd)" \
            --argjson enable_ai "$ENABLE_AI" \
            '{data: ., app_logs: $app_logs, framework: $framework, workspace_root: $workspace_root, enable_ai: $enable_ai}')
    else
        # Build basic payload without app logs but with AI flag
        # Use stdin to avoid "Argument list too long" error with large data
        payload=$(echo "$data" | jq \
            --arg framework "$FRAMEWORK" \
            --arg workspace_root "$(pwd)" \
            --argjson enable_ai "$ENABLE_AI" \
            '{data: ., framework: $framework, workspace_root: $workspace_root, enable_ai: $enable_ai}')
    fi
    
    # Call sidecar's analyze endpoint to add classification and signals
    # This leverages ExecutionAnalyzer, signal extraction, and code resolution
    # Show progress indicator for long-running analysis (especially with AI enabled)
    echo "" >&2
    
    if [ "$ENABLE_AI" = "true" ]; then
        echo -e "${BLUE}ğŸ¤– Running AI-enhanced analysis... (this may take 30-120 minutes for large logs)${NC}" >&2
    else
        echo -e "${BLUE}Running intelligence analysis...${NC}" >&2
    fi
    
    # Create temp file for curl output
    local temp_response=$(mktemp)
    
    # Run curl in background with progress indicator
    (echo "$payload" | \
        curl -s -X POST "${SIDECAR_URL}${endpoint}" \
        -H "Content-Type: application/json" \
        --data-binary @- > "$temp_response" 2>&1) &
    
    local curl_pid=$!
    
    # Show spinner while curl is running
    local spinstr='â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â '
    local spin_chars=('â ‹' 'â ™' 'â ¹' 'â ¸' 'â ¼' 'â ´' 'â ¦' 'â §' 'â ‡' 'â ')
    local spin_index=0
    while kill -0 $curl_pid 2>/dev/null; do
        printf "\r${BLUE}  %-70s [%s]${NC}" "Processing test results and extracting failure patterns..." "${spin_chars[$spin_index]}" >&2
        spin_index=$(( (spin_index + 1) % ${#spin_chars[@]} ))
        sleep 0.15
    done
    
    # Clear spinner line
    printf "\r%-80s\r" " " >&2
    
    # Wait for curl to complete and get exit code
    wait $curl_pid
    local curl_exit=$?
    
    # Read the response
    local enriched=$(cat "$temp_response")
    rm -f "$temp_response"
    
    # Show completion message
    if [ $curl_exit -eq 0 ] && echo "$enriched" | jq empty 2>/dev/null; then
        if [ "$ENABLE_AI" = "true" ]; then
            echo -e "${GREEN}âœ“ AI analysis completed successfully${NC}" >&2
        else
            echo -e "${GREEN}âœ“ Analysis completed${NC}" >&2
        fi
    else
        echo -e "${YELLOW}âš  Analysis completed with warnings${NC}" >&2
    fi
    echo "" >&2
    
    # Check if we got a valid response
    if ! echo "$enriched" | jq empty 2>/dev/null; then
        echo "$data"
        # Show first 200 chars of error for debugging
        local error_preview=$(echo "$enriched" | head -c 200)
        echo -e "${YELLOW}Note: Intelligence analysis failed - ${error_preview}${NC}" >&2
        return
    fi
    
    # Check for API errors
    if echo "$enriched" | jq -e '.detail' > /dev/null 2>&1; then
        local error_detail=$(echo "$enriched" | jq -r '.detail')
        echo "$data"
        echo -e "${YELLOW}Note: Intelligence analysis failed: ${error_detail}${NC}" >&2
        return
    fi
    
    # If analysis endpoint exists and succeeded, use enriched data
    if echo "$enriched" | jq -e '.analyzed' > /dev/null 2>&1; then
        echo "$enriched"
        echo -e "${GREEN}âœ“ Intelligence analysis complete${NC}" >&2
    else
        echo "$data"
        echo -e "${YELLOW}Note: Intelligence analysis not available (using basic parsing)${NC}" >&2
    fi
}

# Apply filters to response
apply_filters() {
    local data="$1"
    
    # Filter by test name (supports wildcards)
    if [ -n "$FILTER_TEST_NAME" ]; then
        # Convert wildcard pattern to regex
        local pattern="${FILTER_TEST_NAME//\*/.*}"
        data=$(echo "$data" | jq --arg pattern "^${pattern}$" '
            if .tests then
                .tests |= map(select(.name | test($pattern)))
            elif .failed_keywords then
                .failed_keywords |= map(select(.name | test($pattern)))
            elif .slowest_tests then
                .slowest_tests |= map(select(.name | test($pattern)))
            else . end
        ')
    fi
    
    # Filter by test ID
    if [ -n "$FILTER_TEST_ID" ]; then
        data=$(echo "$data" | jq --arg id "$FILTER_TEST_ID" '
            if .tests then
                .tests |= map(select(.id == $id))
            else . end
        ')
    fi
    
    # Filter by status
    if [ -n "$FILTER_STATUS" ]; then
        data=$(echo "$data" | jq --arg status "$FILTER_STATUS" '
            if .tests then
                .tests |= map(select(.status == $status))
            elif .failed_keywords and $status == "FAIL" then
                .
            elif .slowest_tests then
                .slowest_tests |= map(select(.status == $status))
            else . end
        ')
    fi
    
    # Filter by time range
    if [ -n "$FILTER_TIME_FROM" ] || [ -n "$FILTER_TIME_TO" ]; then
        local time_filter='true'
        [ -n "$FILTER_TIME_FROM" ] && time_filter="(.start_time >= \"$FILTER_TIME_FROM\")"
        [ -n "$FILTER_TIME_TO" ] && time_filter="$time_filter and (.end_time <= \"$FILTER_TIME_TO\")"
        
        data=$(echo "$data" | jq "
            if .tests then
                .tests |= map(select($time_filter))
            elif .slowest_tests then
                .slowest_tests |= map(select($time_filter))
            else . end
        ")
    fi
    
    # Filter by error code (matches in error messages, exception types, or status codes)
    if [ -n "$FILTER_ERROR_CODE" ]; then
        data=$(echo "$data" | jq --arg code "$FILTER_ERROR_CODE" '
            if .failed_keywords then
                .failed_keywords |= map(select(
                    (.messages[]? | tostring | contains($code)) or
                    (.name | contains($code))
                ))
            elif .failures then
                .failures |= map(select(
                    (.error_message | contains($code)) or
                    (.error_type | contains($code)) or
                    (.status_code | tostring | contains($code))
                ))
            elif .errors then
                .errors |= map(select(.message | contains($code)))
            else . end
        ')
    fi
    
    # Filter by pattern (case-insensitive search in messages, names, errors)
    if [ -n "$FILTER_PATTERN" ]; then
        data=$(echo "$data" | jq --arg pattern "$FILTER_PATTERN" '
            if .failed_keywords then
                .failed_keywords |= map(select(
                    (.name | test($pattern; "i")) or
                    (.messages[]? | tostring | test($pattern; "i"))
                ))
            elif .failures then
                .failures |= map(select(
                    (.title | test($pattern; "i")) or
                    (.error_message | test($pattern; "i")) or
                    (.test_name | test($pattern; "i"))
                ))
            elif .tests then
                .tests |= map(select(
                    (.name | test($pattern; "i")) or
                    (.error_message? | test($pattern; "i"))
                ))
            elif .actions then
                .actions |= map(select(
                    (.action | test($pattern; "i")) or
                    (.selector? | test($pattern; "i"))
                ))
            elif .console_messages then
                .console_messages |= map(select(.text | test($pattern; "i")))
            else . end
        ')
    fi
    
    echo "$data"
}

# Clean and format AI recommendations for better readability (legacy - kept for fallback)
clean_recommendation() {
    local rec="$1"
    
    # Skip unhelpful AI apologies and disclaimers (strict filtering)
    if echo "$rec" | grep -qiE "^(I'm sorry|I am sorry|As an? (AI|large language model)|I don't have|I do not have|I cannot|I can't|My (primary|main) (function|purpose)|Unfortunately|However, I|Please note|It's (important|worth) to note|Keep in mind|Without (more|actual|specific) (context|information|details)|developed by (Deepseek|OpenAI|Anthropic|Claude))"; then
        return
    fi
    
    # Remove mid-sentence disclaimers and hedging
    rec=$(echo "$rec" | sed -E 's/[,;] ?(as an AI|based on my training|I cannot determine|without more context)[^.!?]*(\.|,)/./Ig')
    
    # Remove common prefixes that add no value
    rec=$(echo "$rec" | sed 's/^Root Cause Analysis:[[:space:]]*//')
    rec=$(echo "$rec" | sed 's/^Root Cause:[[:space:]]*//')
    rec=$(echo "$rec" | sed 's/^Analysis:[[:space:]]*//')
    rec=$(echo "$rec" | sed 's/^The root cause of (this issue|the test failure|the error) is (likely |probably )?//')
    rec=$(echo "$rec" | sed 's/^The (error message|test failure|issue) (indicates|suggests) that //')
    rec=$(echo "$rec" | sed 's/^(This|The test) (failure|error) is (likely |probably |most likely )?due to //')
    rec=$(echo "$rec" | sed 's/^(It appears|It seems) (that |like )?//')
    
    # Find complete sentences (at sentence boundaries)
    local sentences=""
    local temp_rec="$rec"
    local char_count=0
    local max_chars=200
    
    # Extract sentences one by one until we hit the limit
    while [ -n "$temp_rec" ] && [ $char_count -lt $max_chars ]; do
        # Extract first sentence (ending with . ! or ?)
        local sentence=$(echo "$temp_rec" | sed -n 's/^\([^.!?]*[.!?]\).*/\1/p')
        
        if [ -z "$sentence" ]; then
            # No sentence boundary found, take what we have
            if [ $char_count -eq 0 ]; then
                # First iteration and no sentence boundary - truncate at word boundary
                sentences=$(echo "$temp_rec" | head -c $max_chars)
                if [ ${#temp_rec} -gt $max_chars ]; then
                    sentences=$(echo "$sentences" | sed 's/\(.*\) [^ ]*$/\1.../')
                fi
            fi
            break
        fi
        
        local sentence_len=${#sentence}
        if [ $((char_count + sentence_len)) -gt $max_chars ]; then
            # Adding this sentence would exceed limit
            break
        fi
        
        sentences="${sentences}${sentence} "
        char_count=$((char_count + sentence_len + 1))
        temp_rec=$(echo "$temp_rec" | sed "s/^[^.!?]*[.!?]//")
        temp_rec=$(echo "$temp_rec" | sed 's/^[[:space:]]*//')
    done
    
    sentences=$(echo "$sentences" | sed 's/[[:space:]]*$//')
    
    # Only output if we have meaningful content (at least 25 chars)
    if [ -n "$sentences" ] && [ ${#sentences} -gt 25 ]; then
        echo "$sentences"
    fi
}

# Summarize recommendations using AI for intelligent, concise summaries
summarize_recommendations_with_ai() {
    local recommendations_json="$1"
    local max_length="${2:-200}"
    
    # Check if we have AI enabled
    if [ "$ENABLE_AI" != "true" ]; then
        # No AI - apply client-side filtering to each recommendation
        echo "$recommendations_json" | jq -r '.[]' | while IFS= read -r rec; do
            if [ -n "$rec" ]; then
                cleaned=$(clean_recommendation "$rec")
                [ -n "$cleaned" ] && echo "$cleaned"
            fi
        done
        return
    fi
    
    # Pre-filter apologies and useless content before sending to AI
    local filtered_json=$(echo "$recommendations_json" | jq -r '.[]' | while IFS= read -r rec; do
        # Skip obvious apologies and disclaimers
        if echo "$rec" | grep -qiE "^(I'm sorry|I am sorry|As an? (AI|large language model)|I don't have|I do not have|I cannot|I can't|Unfortunately|developed by (Deepseek|OpenAI|Anthropic))"; then
            continue
        fi
        echo "$rec"
    done | jq -R -s -c 'split("\n") | map(select(length > 0))')
    
    # If all recommendations filtered out, return empty
    if [ "$(echo "$filtered_json" | jq '. | length')" -eq 0 ]; then
        return
    fi
    
    # Build payload for summarization
    local payload=$(echo "$filtered_json" | jq \
        --argjson max_length "$max_length" \
        '{recommendations: ., max_length: $max_length, ai_provider: "'"${AI_PROVIDER:-}"'"}')
    
    # Call sidecar's summarization endpoint
    local summarized=$(echo "$payload" | \
        curl -s -X POST "${SIDECAR_URL}/summarize-recommendations" \
        -H "Content-Type: application/json" \
        --data-binary @- 2>/dev/null)
    
    # Check if AI summarization succeeded
    if echo "$summarized" | jq -e '.summarized == true' > /dev/null 2>&1; then
        # Still apply final filtering to AI output
        echo "$summarized" | jq -r '.recommendations[]' | while IFS= read -r rec; do
            # Skip if AI still generated apologies
            if echo "$rec" | grep -qiE "^(I'm sorry|I am sorry|As an? (AI|model)|I don't have|I cannot|developed by)"; then
                continue
            fi
            echo "$rec"
        done
        [ "${DEBUG:-false}" = "true" ] && echo "DEBUG: AI summarized $(echo "$summarized" | jq -r '.original_count') â†’ $(echo "$summarized" | jq -r '.summarized_count') recommendations" >&2
    else
        # Fallback: Use clean_recommendation for each item
        echo "$filtered_json" | jq -r '.[]' | while IFS= read -r rec; do
            if [ -n "$rec" ]; then
                cleaned=$(clean_recommendation "$rec")
                [ -n "$cleaned" ] && echo "$cleaned"
            fi
        done
    fi
}

# Capture start time for AI analysis duration tracking
AI_START_TIME=$(date +%s)

# Enrich with intelligence analysis (automatic)
ENRICHED_RESPONSE=$(enrich_with_intelligence "$RESPONSE")

# Calculate AI analysis duration
AI_END_TIME=$(date +%s)
export AI_ANALYSIS_DURATION=$((AI_END_TIME - AI_START_TIME))

# Apply filters
FILTERED_RESPONSE=$(apply_filters "$ENRICHED_RESPONSE")

# Display intelligence summary (if available)
if echo "$FILTERED_RESPONSE" | jq -e '.intelligence_summary' > /dev/null 2>&1; then
    echo ""
    echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BLUE}Intelligence Analysis Summary${NC}"
    echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    
    # Show classification breakdown
    if echo "$FILTERED_RESPONSE" | jq -e '.intelligence_summary.classifications' > /dev/null 2>&1; then
        echo -e "${YELLOW}Failure Classifications:${NC}"
        echo "$FILTERED_RESPONSE" | jq -r '.intelligence_summary.classifications | to_entries[] | "  â€¢ \(.key): \(.value)"'
    fi
    
    # Show signal summary
    if echo "$FILTERED_RESPONSE" | jq -e '.intelligence_summary.signals' > /dev/null 2>&1; then
        echo -e "${YELLOW}Detected Signals:${NC}"
        echo "$FILTERED_RESPONSE" | jq -r '.intelligence_summary.signals | to_entries[] | "  â€¢ \(.key): \(.value)"'
    fi
    
    # Show AI-enhanced test insights
    if echo "$FILTERED_RESPONSE" | jq -e '.enriched_tests[] | select(.ai_enhanced == true)' > /dev/null 2>&1; then
        echo -e "${YELLOW}AI-Enhanced Test Analysis:${NC}"
        
        shown_count=0
        max_insights=10
        total=$(echo "$FILTERED_RESPONSE" | jq '[.enriched_tests[] | select(.ai_enhanced == true and .ai_reasoning != null)] | length')
        
        while IFS= read -r test_insight; do
            if [ -z "$test_insight" ]; then
                continue
            fi
            
            if [ $shown_count -ge $max_insights ]; then
                if [ $total -gt $max_insights ]; then
                    echo ""
                    echo "  ... and $((total - max_insights)) more AI-enhanced tests (use filters to see specific tests)"
                fi
                break
            fi
            
            test_id=$(echo "$test_insight" | jq -r '.id // "N/A"')
            test_name=$(echo "$test_insight" | jq -r '.name')
            classification=$(echo "$test_insight" | jq -r '.classification')
            confidence=$(echo "$test_insight" | jq -r '.confidence')
            reasoning=$(echo "$test_insight" | jq -r '.reasoning')
            
            # Clean AI reasoning - aggressively remove apologies and disclaimers
            reasoning=$(echo "$reasoning" | sed -E '
                # Remove apology/disclaimer sentences at start
                /^[[:space:]]*(I'\''m sorry|As an? (AI|large language model)|Unfortunately|However, I|My (training|primary|main) (data|function))/d
                /^[[:space:]]*I (don'\''t|do not|cannot|can'\''t) (have|provide|access)/d
                /developed by (Deepseek|OpenAI|Anthropic|Claude)/Id
                # Remove generic hedging phrases
                /^[[:space:]]*(Please note|It'\''s (important|worth) (noting|to note)|Keep in mind|Based on (my|the) (training|analysis))/d
                /^[[:space:]]*Without (more|actual|specific|complete) (context|information|details)/d
                # Remove empty lines
                /^[[:space:]]*$/d
            ')
            
            # Additional inline cleanup - remove mid-sentence disclaimers
            reasoning=$(echo "$reasoning" | sed -E 's/[,;] ?(as an AI|based on my training data|I cannot determine)[^.!?]*(\.|,)/./Ig')
            
            # Skip if reasoning is empty or too short after cleaning
            if [ -z "$reasoning" ] || [ $(echo "$reasoning" | wc -w) -lt 10 ]; then
                continue
            fi
            
            # Use AI to intelligently summarize reasoning if enabled, otherwise use sentence-boundary truncation
            if [ "$ENABLE_AI" = "true" ] && [ ${#reasoning} -gt 200 ]; then
                # Create JSON array with single reasoning text for AI summarization
                reasoning_json=$(echo "$reasoning" | jq -R -s -c '[.]')
                truncated=$(summarize_recommendations_with_ai "$reasoning_json" 200 | head -1)
                
                # Fallback to manual if AI summarization failed
                if [ -z "$truncated" ] || [ $(echo "$truncated" | wc -w) -lt 10 ]; then
                    truncated=$(clean_recommendation "$reasoning")
                fi
            else
                # Fallback: Use clean_recommendation for sentence-boundary-aware truncation
                truncated=$(clean_recommendation "$reasoning")
            fi
            
            # Skip if truncated result is empty
            if [ -z "$truncated" ]; then
                continue
            fi
            
            # Format classification for better readability
            class_display=$(echo "$classification" | sed 's/_/ > /g')
            
            echo ""
            echo "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
            echo "  â”‚ ${test_id}: ${test_name}"
            echo "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
            echo "  ğŸ“Š Classification: ${class_display}"
            echo "  ğŸ¯ Confidence: ${confidence}"
            echo "  "
            echo "  ğŸ’¡ Root Cause Analysis:"
            echo "  ${truncated}"
            
            shown_count=$((shown_count + 1))
        done < <(echo "$FILTERED_RESPONSE" | jq -c '.enriched_tests[] | select(.ai_enhanced == true and .ai_reasoning != null) | {
            id: .id,
            name: .name,
            classification: .classification.failure_type,
            confidence: .classification.confidence,
            reasoning: .ai_reasoning
        }')
        
        echo ""
    elif echo "$FILTERED_RESPONSE" | jq -e '.intelligence_summary.recommendations' > /dev/null 2>&1; then
        # Fallback to generic recommendations if no AI-enhanced tests
        echo -e "${YELLOW}Recommendations:${NC}"
        
        # Get unique recommendations (deduplicate similar ones)
        recommendations=$(echo "$FILTERED_RESPONSE" | jq -r '.intelligence_summary.recommendations[]' | sort -u)
        
        # Collect recommendations into JSON array for batch AI summarization
        recommendations_array=$(echo "$recommendations" | jq -R -s -c 'split("\n") | map(select(length > 0))')
        
        # Summarize with AI if enabled, otherwise use clean_recommendation
        if [ "$ENABLE_AI" = "true" ]; then
            summarized_recs=$(summarize_recommendations_with_ai "$recommendations_array" 200)
        else
            # Fallback to client-side cleaning
            summarized_recs=""
            while IFS= read -r rec; do
                if [ -n "$rec" ]; then
                    cleaned=$(clean_recommendation "$rec")
                    if [ -n "$cleaned" ]; then
                        summarized_recs="${summarized_recs}${cleaned}"$'\n'
                    fi
                fi
            done <<< "$recommendations"
        fi
        
        # Display summarized recommendations
        shown_count=0
        max_recommendations=10
        
        while IFS= read -r rec; do
            if [ -n "$rec" ]; then
                echo "  âœ“ $rec"
                shown_count=$((shown_count + 1))
                
                # Limit to top N recommendations
                if [ $shown_count -ge $max_recommendations ]; then
                    total_recs=$(echo "$summarized_recs" | grep -c '^.')
                    if [ $total_recs -gt $max_recommendations ]; then
                        remaining=$((total_recs - max_recommendations))
                        echo "  ... and $remaining more recommendations (filtered for clarity)"
                    fi
                    break
                fi
            fi
        done <<< "$summarized_recs"
        
        # If no useful recommendations after filtering
        if [ $shown_count -eq 0 ]; then
            echo "  â€¢ Check API endpoint configuration and request parameters"
            echo "  â€¢ Review error logs for detailed failure information"
            echo "  â€¢ Verify test environment setup and connectivity"
        fi
    fi
    
    # Show top failure details with code references
    if echo "$FILTERED_RESPONSE" | jq -e '.intelligence_summary.top_failures' > /dev/null 2>&1; then
        TOP_FAILURES_COUNT=$(echo "$FILTERED_RESPONSE" | jq '.intelligence_summary.top_failures | length')
        if [ "$TOP_FAILURES_COUNT" -gt 0 ]; then
            echo ""
            echo -e "${YELLOW}Top Failure Details:${NC}"
            echo ""
            
            # Table header
            printf "  %-40s %-25s %-12s %s\n" "Test Case" "Failure Type" "Confidence" "Error Summary"
            printf "  %-40s %-25s %-12s %s\n" "$(printf '%.0sâ”€' {1..40})" "$(printf '%.0sâ”€' {1..25})" "$(printf '%.0sâ”€' {1..12})" "$(printf '%.0sâ”€' {1..50})"
            
            # Table rows
            echo "$FILTERED_RESPONSE" | jq -r '.intelligence_summary.top_failures[] | 
                [.test_name, .failure_type, (.confidence | tostring), .reason] | @tsv' | \
            while IFS=$'\t' read -r test_name failure_type confidence reason; do
                # Truncate long test names to fit column width
                if [ ${#test_name} -gt 38 ]; then
                    test_name="${test_name:0:35}..."
                fi
                
                # Truncate long failure types
                if [ ${#failure_type} -gt 23 ]; then
                    failure_type="${failure_type:0:20}..."
                fi
                
                # Truncate long error messages to fit and add ...
                if [ ${#reason} -gt 48 ]; then
                    reason="${reason:0:45}..."
                fi
                
                # Color confidence based on value
                if (( $(echo "$confidence > 0.8" | bc -l 2>/dev/null || echo 0) )); then
                    conf_color="${GREEN}"
                elif (( $(echo "$confidence > 0.6" | bc -l 2>/dev/null || echo 0) )); then
                    conf_color="${YELLOW}"
                else
                    conf_color="${RED}"
                fi
                
                printf "  %-40s %-25s ${conf_color}%-12s${NC} %s\n" "$test_name" "$failure_type" "$confidence" "$reason"
            done
            
            echo ""
            
            # Show additional details for code references if available
            if echo "$FILTERED_RESPONSE" | jq -e '.intelligence_summary.top_failures[] | select(.code_reference != null)' > /dev/null 2>&1; then
                echo -e "${BLUE}  Code References:${NC}"
                echo "$FILTERED_RESPONSE" | jq -r '.intelligence_summary.top_failures[] | select(.code_reference != null) | 
                    "    â€¢ \(.test_name): \(.code_reference)"'
                echo ""
            fi
        else
            # Debug: top_failures array exists but is empty
            [ "$VERBOSE" = "true" ] && echo -e "${YELLOW}[Debug] top_failures array is empty${NC}" >&2
        fi
    else
        # Debug: top_failures field is missing
        [ "$VERBOSE" = "true" ] && echo -e "${YELLOW}[Debug] .intelligence_summary.top_failures field missing from response${NC}" >&2
        [ "$VERBOSE" = "true" ] && echo -e "${YELLOW}[Debug] Available fields: $(echo "$FILTERED_RESPONSE" | jq -r '.intelligence_summary | keys | join(", ")')${NC}" >&2
    fi
    
    echo ""
fi

# Display application log correlation summary (if available)
if echo "$FILTERED_RESPONSE" | jq -e '.correlation_summary.total_correlated' > /dev/null 2>&1; then
    TOTAL_CORR=$(echo "$FILTERED_RESPONSE" | jq -r '.correlation_summary.total_correlated')
    if [ "$TOTAL_CORR" -gt 0 ]; then
        echo ""
        echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${BLUE}   Application Log Correlation Results${NC}"
        echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        
        AVG_CONF=$(echo "$FILTERED_RESPONSE" | jq -r '.correlation_summary.avg_confidence')
        TOTAL_APP_LOGS=$(echo "$FILTERED_RESPONSE" | jq -r '.correlation_summary.total_app_logs_analyzed')
        SAMPLED_LOGS=$(echo "$FILTERED_RESPONSE" | jq -r '.correlation_summary.sampled_logs_count')
        
        echo "  Tests Correlated: $TOTAL_CORR"
        echo "  Average Confidence: $(printf '%.2f' $AVG_CONF)"
        echo "  App Logs Analyzed: $TOTAL_APP_LOGS"
        echo "  After Sampling: $SAMPLED_LOGS"
        echo ""
        
        # Show correlation methods used
        echo -e "${YELLOW}Correlation Methods Used:${NC}"
        echo "$FILTERED_RESPONSE" | jq -r '.correlation_summary.correlation_methods | to_entries[] | 
            "  â€¢ \(.key): \(.value) tests"'
        echo ""
        
        # Show top correlated app errors
        CORR_ERRORS=$(echo "$FILTERED_RESPONSE" | jq '.correlated_app_errors | length')
        if [ "$CORR_ERRORS" -gt 0 ]; then
            DISPLAY_COUNT=$((CORR_ERRORS < 5 ? CORR_ERRORS : 5))
            echo -e "${RED}Top Correlated Application Errors (showing $DISPLAY_COUNT of $CORR_ERRORS):${NC}"
            echo "$FILTERED_RESPONSE" | jq -r '.correlated_app_errors[0:5][] | 
                "  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n" +
                "  Test: \(.test_name)\n" +
                "    Method: \(.correlation_method) (confidence: \(.confidence))\n" +
                "    App Errors Found: \(.app_logs | length)\n" +
                "    Correlation Details: \(.correlation_details)\n" +
                (.app_logs[0:3][] | "      [\(.level)] \(.timestamp) - \(.message[:100])\n" +
                (if .service then "              Service: \(.service)\n" else "" end) +
                (if .trace_id then "              Trace ID: \(.trace_id)\n" else "" end)) +
                (if (.app_logs | length) > 3 then "      ... and \((.app_logs | length) - 3) more errors\n" else "" end)'
            echo ""
        fi
    fi
fi

# Format duration into human-readable format
format_duration() {
    local total_seconds=$1
    
    if [ $total_seconds -lt 60 ]; then
        # Less than 1 minute: show seconds
        echo "${total_seconds}s"
    elif [ $total_seconds -lt 3600 ]; then
        # Less than 1 hour: show minutes and seconds
        local minutes=$((total_seconds / 60))
        local seconds=$((total_seconds % 60))
        if [ $seconds -eq 0 ]; then
            echo "${minutes}m"
        else
            echo "${minutes}m ${seconds}s"
        fi
    elif [ $total_seconds -lt 86400 ]; then
        # Less than 1 day: show hours and minutes
        local hours=$((total_seconds / 3600))
        local minutes=$(((total_seconds % 3600) / 60))
        if [ $minutes -eq 0 ]; then
            echo "${hours}h"
        else
            echo "${hours}h ${minutes}m"
        fi
    else
        # 1 day or more: show days and hours
        local days=$((total_seconds / 86400))
        local hours=$(((total_seconds % 86400) / 3600))
        if [ $hours -eq 0 ]; then
            echo "${days}d"
        else
            echo "${days}d ${hours}h"
        fi
    fi
}

# Display AI usage summary if AI was used
if echo "$FILTERED_RESPONSE" | jq -e '.ai_usage.total_tokens' > /dev/null 2>&1; then
    echo ""
    echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${BLUE}         AI LOG ANALYSIS SUMMARY${NC}"
    echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    
    PROVIDER=$(echo "$FILTERED_RESPONSE" | jq -r '.ai_usage.provider')
    MODEL=$(echo "$FILTERED_RESPONSE" | jq -r '.ai_usage.model')
    PROMPT_TOKENS=$(echo "$FILTERED_RESPONSE" | jq -r '.ai_usage.prompt_tokens')
    COMPLETION_TOKENS=$(echo "$FILTERED_RESPONSE" | jq -r '.ai_usage.completion_tokens')
    TOTAL_TOKENS=$(echo "$FILTERED_RESPONSE" | jq -r '.ai_usage.total_tokens')
    COST=$(echo "$FILTERED_RESPONSE" | jq -r '.ai_usage.cost')
    
    # Count analyzed tests
    ANALYZED_TESTS=$(echo "$FILTERED_RESPONSE" | jq '.enriched_tests | length')
    
    echo ""
    echo -e "${YELLOW}AI Configuration:${NC}"
    echo "  â€¢ Provider: ${PROVIDER^}"
    echo "  â€¢ Model: $MODEL"
    echo ""
    echo -e "${YELLOW}AI Analysis Statistics:${NC}"
    echo "  âœ“ Total Tests Analyzed: $ANALYZED_TESTS"
    echo "  âœ“ AI-Enhanced Classifications: $ANALYZED_TESTS"
    echo "  âœ“ Total Time Taken: $(format_duration $AI_ANALYSIS_DURATION)"
    echo ""
    echo -e "${YELLOW}Token Usage & Cost:${NC}"
    echo "  â€¢ Prompt Tokens: $PROMPT_TOKENS"
    echo "  â€¢ Completion Tokens: $COMPLETION_TOKENS"
    echo "  â€¢ Total Tokens: $TOTAL_TOKENS"
    
    # Only show cost for cloud providers (not self-hosted)
    if [[ "$PROVIDER" != "selfhosted" && "$PROVIDER" != "ollama" ]]; then
        echo "  â€¢ Total Cost: \$$(printf '%.4f' $COST)"
    fi
    
    if [ "$ANALYZED_TESTS" -gt 0 ]; then
        AVG_TOKENS=$((TOTAL_TOKENS / ANALYZED_TESTS))
        echo "  â€¢ Avg Tokens/Test: $AVG_TOKENS"
        
        # Only show average cost for cloud providers
        if [[ "$PROVIDER" != "selfhosted" && "$PROVIDER" != "ollama" ]]; then
            AVG_COST=$(awk "BEGIN {printf \"%.4f\", $COST / $ANALYZED_TESTS}")
            echo "  â€¢ Avg Cost/Test: \$$AVG_COST"
        fi
    fi
    
    # Cost comparison
    if [ "$PROVIDER" = "openai" ] && [[ "$MODEL" == *"gpt-3.5"* ]]; then
        GPT4_COST=$(awk "BEGIN {printf \"%.2f\", $COST * 30}")
        SAVINGS=$(awk "BEGIN {printf \"%.2f\", $GPT4_COST - $COST}")
        SAVINGS_PCT=$(awk "BEGIN {printf \"%.0f\", ($SAVINGS / $GPT4_COST) * 100}")
        
        echo ""
        echo -e "${GREEN}Cost Savings:${NC}"
        echo "  â€¢ Using $MODEL: \$$COST"
        echo "  â€¢ Same with gpt-4: ~\$$GPT4_COST"
        echo "  â€¢ Savings: ~\$$SAVINGS ($SAVINGS_PCT% reduction)"
    fi
    
    echo ""
    echo -e "${BLUE}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
fi

# Display results based on framework
display_results() {
    local response="$1"
    
    # If response has intelligence wrapper, extract the data
    local data="$response"
    if echo "$response" | jq -e '.analyzed' > /dev/null 2>&1; then
        data=$(echo "$response" | jq '.data')
    fi
    
    case "$FRAMEWORK" in
        robot)
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo -e "${GREEN}           Robot Framework Results${NC}"
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo ""
            
            # Suite info
            SUITE_NAME=$(echo "$data" | jq -r '.suite.name')
            SUITE_STATUS=$(echo "$data" | jq -r '.suite.status')
            echo -e "${BLUE}Suite:${NC} $SUITE_NAME"
            
            if [ "$SUITE_STATUS" = "PASS" ]; then
                echo -e "${BLUE}Status:${NC} ${GREEN}$SUITE_STATUS${NC}"
            else
                echo -e "${BLUE}Status:${NC} ${RED}$SUITE_STATUS${NC}"
            fi
            echo ""
            
            # Statistics
            TOTAL=$(echo "$data" | jq -r '.suite.total_tests')
            PASSED=$(echo "$data" | jq -r '.suite.passed_tests')
            FAILED=$(echo "$data" | jq -r '.suite.failed_tests')
            ELAPSED=$(echo "$data" | jq -r '.suite.elapsed_ms')
            
            # Convert milliseconds to seconds and format using format_duration
            ELAPSED_SECONDS=$((ELAPSED / 1000))
            DURATION_STR=$(format_duration $ELAPSED_SECONDS)
            
            echo -e "${BLUE}Test Statistics:${NC}"
            echo "  Total:    $TOTAL"
            echo -e "  Passed:   ${GREEN}$PASSED${NC}"
            echo -e "  Failed:   ${RED}$FAILED${NC}"
            echo "  Duration: ${DURATION_STR}"
            echo ""
            
            # Failed keywords - show top 5 with error details
            FAILED_KW_COUNT=$(echo "$data" | jq '.failed_keywords | length')
            if [ "$FAILED_KW_COUNT" -gt 0 ]; then
                DISPLAY_KW_COUNT=$((FAILED_KW_COUNT < 5 ? FAILED_KW_COUNT : 5))
                echo -e "${RED}Top Failed Keywords (showing $DISPLAY_KW_COUNT of $FAILED_KW_COUNT):${NC}"
                echo "$data" | jq -r '.failed_keywords[0:5][] | 
                    "  âŒ \(.name)" + 
                    (if .library != "" then " [\(.library)]" else "" end) + 
                    (if .error then "\n     Error: \(.error)" else "" end)'
                echo ""
            fi
            
            # Slowest tests
            SLOWEST_TESTS=$(echo "$data" | jq '.slowest_tests | length')
            if [ "$SLOWEST_TESTS" -gt 0 ]; then
                DISPLAY_COUNT=$((SLOWEST_TESTS < 5 ? SLOWEST_TESTS : 5))
                echo -e "${YELLOW}Slowest Tests (Top $DISPLAY_COUNT):${NC}"
                
                # Format each test duration using format_duration function
                echo "$data" | jq -r '.slowest_tests[0:5][] | "\(.elapsed_ms)|\(.name)"' | \
                while IFS='|' read -r elapsed_ms test_name; do
                    elapsed_seconds=$((elapsed_ms / 1000))
                    duration_str=$(format_duration $elapsed_seconds)
                    
                    # Truncate long test names for better display (max 80 chars)
                    if [ ${#test_name} -gt 80 ]; then
                        test_name="${test_name:0:77}..."
                    fi
                    
                    printf "  %-85s %s\n" "$test_name" "$duration_str"
                done
                
                echo ""
            fi
            ;;
            
        cypress)
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo -e "${GREEN}           Cypress Test Results${NC}"
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo ""
            
            TOTAL=$(echo "$data" | jq -r '.statistics.total_tests')
            PASSED=$(echo "$data" | jq -r '.statistics.passed_tests')
            FAILED=$(echo "$data" | jq -r '.statistics.failed_tests')
            
            echo -e "${BLUE}Test Statistics:${NC}"
            echo "  Total:  $TOTAL"
            echo -e "  Passed: ${GREEN}$PASSED${NC}"
            echo -e "  Failed: ${RED}$FAILED${NC}"
            echo ""
            
            FAILURES=$(echo "$data" | jq '.failures | length')
            if [ "$FAILURES" -gt 0 ]; then
                echo -e "${RED}Failed Tests:${NC}"
                echo "$data" | jq -r '.failures[] | "  âŒ \(.title): \(.error_message)"'
            fi
            ;;
            
        playwright)
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo -e "${GREEN}          Playwright Trace Analysis${NC}"
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo ""
            
            ACTION_COUNT=$(echo "$data" | jq '.actions | length')
            NETWORK_COUNT=$(echo "$data" | jq '.network_calls | length')
            
            echo -e "${BLUE}Trace Summary:${NC}"
            echo "  Actions:       $ACTION_COUNT"
            echo "  Network Calls: $NETWORK_COUNT"
            echo ""
            
            if [ "$ACTION_COUNT" -gt 0 ]; then
                echo -e "${BLUE}Actions (First 10):${NC}"
                echo "$data" | jq -r '.actions[0:10][] | "  â€¢ \(.action): \(.selector // "N/A")"'
            fi
            ;;
            
        behave)
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo -e "${GREEN}            Behave BDD Results${NC}"
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo ""
            
            FEATURE_COUNT=$(echo "$data" | jq '.features | length')
            SCENARIO_COUNT=$(echo "$data" | jq '.statistics.total_scenarios')
            PASSED=$(echo "$data" | jq '.statistics.passed_scenarios')
            FAILED=$(echo "$data" | jq '.statistics.failed_scenarios')
            
            echo -e "${BLUE}BDD Statistics:${NC}"
            echo "  Features:  $FEATURE_COUNT"
            echo "  Scenarios: $SCENARIO_COUNT"
            echo -e "  Passed:    ${GREEN}$PASSED${NC}"
            echo -e "  Failed:    ${RED}$FAILED${NC}"
            ;;
            
        java)
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo -e "${GREEN}       Java Cucumber Step Definitions${NC}"
            echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
            echo ""
            
            STEP_COUNT=$(echo "$data" | jq '.step_definitions | length')
            
            echo -e "${BLUE}Step Definitions Found:${NC} $STEP_COUNT"
            echo ""
            
            if [ "$STEP_COUNT" -gt 0 ]; then
                # Group by type
                GIVEN_COUNT=$(echo "$data" | jq '[.step_definitions[] | select(.step_type == "Given")] | length')
                WHEN_COUNT=$(echo "$data" | jq '[.step_definitions[] | select(.step_type == "When")] | length')
                THEN_COUNT=$(echo "$data" | jq '[.step_definitions[] | select(.step_type == "Then")] | length')
                
                echo -e "${BLUE}By Type:${NC}"
                echo "  Given: $GIVEN_COUNT"
                echo "  When:  $WHEN_COUNT"
                echo "  Then:  $THEN_COUNT"
                echo ""
                
                echo -e "${BLUE}Step Definitions:${NC}"
                echo "$data" | jq -r '.step_definitions[] | "  \(.step_type): \(.pattern)"'
            fi
            ;;
    esac
}

# Display to console
echo ""
display_results "$FILTERED_RESPONSE"

echo ""
echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
echo -e "${GREEN}âœ“ Parsing complete!${NC}"

# Save to file if specified
if [ -n "$OUTPUT_FILE" ]; then
    echo "$FILTERED_RESPONSE" | jq . > "$OUTPUT_FILE"
    echo -e "${BLUE}Filtered results saved to: ${OUTPUT_FILE}${NC}"
else
    # Save to default file with timestamp
    DEFAULT_OUTPUT="${LOG_FILE}.parsed.$(date +%Y%m%d_%H%M%S).json"
    echo "$FILTERED_RESPONSE" | jq . > "$DEFAULT_OUTPUT"
    echo -e "${BLUE}Full results saved to: ${DEFAULT_OUTPUT}${NC}"
fi

# Upload to sidecar for API access (if log size is reasonable)
LOG_SIZE=$(wc -c < "$LOG_FILE")
MAX_SIZE=$((10 * 1024 * 1024))  # 10MB limit

if [ "$LOG_SIZE" -lt "$MAX_SIZE" ]; then
    echo ""
    echo -e "${BLUE}Uploading parsed results to sidecar for API access...${NC}"
    
    # Generate unique log ID based on file path and timestamp
    LOG_ID=$(echo "${LOG_FILE}_$(date +%s)" | md5sum | cut -d' ' -f1)
    
    # Upload via stdin to avoid argument length limits
    UPLOAD_RESPONSE=$(echo "$FILTERED_RESPONSE" | curl -s -X POST "${SIDECAR_URL}/logs/${LOG_ID}" \
        -H "Content-Type: application/json" \
        --data-binary @- 2>&1)
    
    UPLOAD_STATUS=$?
    
    if [ $UPLOAD_STATUS -eq 0 ] && echo "$UPLOAD_RESPONSE" | jq -e '.id' > /dev/null 2>&1; then
        echo -e "${GREEN}âœ“${NC} Results uploaded successfully"
        echo -e "${BLUE}Access via API:${NC}"
        echo "  GET  ${SIDECAR_URL}/logs/${LOG_ID}"
        echo "  GET  ${SIDECAR_URL}/logs/${LOG_ID}/summary"
        echo "  GET  ${SIDECAR_URL}/logs/${LOG_ID}/failures"
    else
        echo -e "${YELLOW}Note: API upload endpoint not available${NC}"
        if [ $UPLOAD_STATUS -ne 0 ]; then
            echo -e "${YELLOW}Curl error: ${UPLOAD_RESPONSE}${NC}"
        elif [ -n "$UPLOAD_RESPONSE" ]; then
            echo -e "${YELLOW}Response: ${UPLOAD_RESPONSE}${NC}"
        fi
        SAVED_TO="${OUTPUT_FILE:-results.json}"
        echo -e "${YELLOW}Results available locally in: ${SAVED_TO}${NC}"
    fi
else
    echo ""
    echo -e "${YELLOW}Note: Log file too large ($(($LOG_SIZE / 1024 / 1024))MB) for API upload${NC}"
    echo -e "${YELLOW}Maximum size: 10MB. Results saved locally only.${NC}"
fi

echo ""
